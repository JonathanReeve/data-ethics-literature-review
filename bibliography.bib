@Article{boyd_2012,
  author =       {boyd, danah and Crawford, Kate},
  title =        {Critical Questions for Big Data},
  year =         2012,
  volume =       15,
  number =       5,
  month =        {Jun},
  pages =        {662–679},
  issn =         {1468-4462},
  doi =          {10.1080/1369118x.2012.678878},
  url =          {http://dx.doi.org/10.1080/1369118X.2012.678878},
  journal =      {Information, Communication & Society},
  publisher =    {Informa UK Limited}
}

@article{berry2011computational,
  title={The computational turn: Thinking about the digital humanities},
  author={Berry, David M},
  journal={Culture machine},
  volume={12},
  year={2011}
}

@misc{dignazio_5_2020,
	title = {5 {Questions} on {Data} and {Context} with {Desmond} {Patton}},
	url = {https://medium.com/data-feminism/5-questions-on-data-and-context-with-desmond-patton-5a09661cbbc6},
	abstract = {By Catherine D’Ignazio with editing by Isabel Carter},
	language = {en},
	urldate = {2021-02-03},
	journal = {Medium},
	author = {D'Ignazio, Catherine},
	month = feb,
	year = {2020},
}

@Article{Frey_2018,
  author       = {Frey, William R. and Patton, Desmond U. and Gaskell, Michael
                  B. and McGregor, Kyle A.},
  title        = {Artificial Intelligence and Inclusion: Formerly Gang-Involved
                  Youth as Domain Experts for Analyzing Unstructured Twitter
                  Data},
  year         = 2018,
  volume       = 38,
  number       = 1,
  month        = {Jul},
  pages        = {42–56},
  issn         = {1552-8286},
  doi          = {10.1177/0894439318788314},
  url          = {http://dx.doi.org/10.1177/0894439318788314},
  journal      = {Social Science Computer Review},
  publisher    = {SAGE Publications}
}
@article{thomas1996introduction,
  title={Introduction: A debate about the ethics of fair practices for collecting social science data in cyberspace},
  author={Thomas, Jim},
  journal={The information society},
  volume={12},
  number={2},
  pages={107--118},
  year={1996},
  publisher={Taylor \& Francis}
}

@book{resnik2005ethics,
  title={The ethics of science: An introduction},
  author={Resnik, David B},
  year={2005},
  publisher={Routledge}
}

@article{stark2019data,
  title={Data is the new what? Popular metaphors \& professional ethics in emerging data culture},
  author={Stark, Luke and Hoffmann, Anna Lauren},
  year={2019},
  publisher={SocArXiv}
}

@article{mittelstadt2016ethics,
  title={The ethics of big data: current and foreseeable issues in biomedical contexts},
  author={Mittelstadt, Brent Daniel and Floridi, Luciano},
  journal={The ethics of biomedical big data},
  pages={445--480},
  year={2016},
  publisher={Springer}
}

@article{richards2014big,
  title={Big data ethics},
  author={Richards, Neil M and King, Jonathan H},
  journal={Wake Forest L. Rev.},
  volume={49},
  pages={393},
  year={2014},
  publisher={HeinOnline}
}

@book{buchanan2014case,
  title={Case studies in library and information science ethics},
  author={Buchanan, Elizabeth A and Henderson, Kathrine A},
  year={2014},
  publisher={McFarland}
}

@incollection{van2016data,
  title={Data science in action},
  author={Van Der Aalst, Wil},
  booktitle={Process mining},
  pages={3--23},
  year={2016},
  publisher={Springer}
}

@article{taylor2016ethics,
  title={The ethics of big data as a public good: which public? Whose good?},
  author={Taylor, Linnet},
  journal={Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume={374},
  number={2083},
  pages={20160126},
  year={2016},
  publisher={The Royal Society}
}

@book{richterich2018big,
  title={The big data agenda: Data ethics and critical data studies},
  author={Richterich, Annika},
  year={2018},
  publisher={University of Westminster Press}
}

@book{mittelstadt2016ethics,
  title={The ethics of biomedical big data},
  author={Mittelstadt, Brent Daniel and Floridi, Luciano},
  volume={29},
  year={2016},
  publisher={Springer}
}
@article{fairfield2014big,
  title={Big data, big problems: Emerging issues in the ethics of data science and journalism},
  author={Fairfield, Joshua and Shtein, Hannah},
  journal={Journal of Mass Media Ethics},
  volume={29},
  number={1},
  pages={38--51},
  year={2014},
  publisher={Taylor \& Francis}
}

@article{barocas2017engaging,
  title={Engaging the ethics of data science in practice},
  author={Barocas, Solon and Boyd, Danah},
  journal={Communications of the ACM},
  volume={60},
  number={11},
  pages={23--25},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@article{leonelli2016locating,
  title={Locating ethics in data science: responsibility and accountability in global and distributed knowledge production systems},
  author={Leonelli, Sabina},
  journal={Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume={374},
  number={2083},
  pages={20160122},
  year={2016},
  publisher={The Royal Society}
}

@article{metcalf2016human,
  title={Where are human subjects in big data research? The emerging ethics divide},
  author={Metcalf, Jacob and Crawford, Kate},
  journal={Big Data \& Society},
  volume={3},
  number={1},
  pages={2053951716650211},
  year={2016},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{o2016ethics,
  title={Ethics for big data and analytics},
  author={O'Leary, Daniel E},
  journal={IEEE Intelligent Systems},
  volume={31},
  number={4},
  pages={81--84},
  year={2016},
  publisher={IEEE}
}

@article{pickersgill2012co,
  title={The co-production of science, ethics, and emotion},
  author={Pickersgill, Martyn},
  journal={Science, Technology, \& Human Values},
  volume={37},
  number={6},
  pages={579--603},
  year={2012},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{zwitter2014big,
  title={Big data ethics},
  author={Zwitter, Andrej},
  journal={Big Data \& Society},
  volume={1},
  number={2},
  pages={2053951714559253},
  year={2014},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{hand2018aspects,
  title={Aspects of data ethics in a changing world: Where are we now?},
  author={Hand, David J},
  journal={Big data},
  volume={6},
  number={3},
  pages={176--190},
  year={2018},
  publisher={Mary Ann Liebert, Inc., publishers 140 Huguenot Street, 3rd Floor New~…}
}

@article{crawford2014big,
  title={Big Data| critiquing Big Data: Politics, ethics, epistemology| special section introduction},
  author={Crawford, Kate and Gray, Mary L and Miltner, Kate},
  journal={International Journal of Communication},
  volume={8},
  pages={10},
  year={2014}
}

@misc{glanz_bookclub_2020,
	title = {Bookclub on {Data} {Science} {Ethics} · {Teach} {Data} {Science}},
	url = {https://teachdatascience.com/bookclub/},
  author = {Glanz, Hunter},
	urldate = {2021-02-14},
	journal = {Teach Data Science},
}

@misc{dunn_tech_2020,
	title = {Tech for good isn't a thing},
	url = {https://relay.substack.com/p/tech-for-good-isnt-a-thing},
	abstract = {Because 'tech for bad' isn't a thing either},
	urldate = {2021-02-14},
  date = {2020-02-03},
	author = {Dunn, Alix},
}

@misc{klein_ethics_2020,
	title = {Ethics and {Governance} of {AI} {Reading} {List} {\textbar} {Berkman} {Klein} {Center}},
	url = {https://cyber.harvard.edu/ethics-and-governance-ai-reading-list},
  author = {The Berkman Klein Center for Internet & Society},
	abstract = {{\textless}p dir="ltr"{\textgreater}Our work is designed to catalyze and advance AI in the public interest, with the aim of including a broad set of voices in understanding and addressing the human impacts of AI. The Berkman Klein Center, in collaboration with the MIT Media Lab, serves as a collaborative platform through which stakeholders working across disciplines, sectors, and geographies can meet, engage, learn, and share. This document serves as a curated, evolving list of resources related to the topic of the ethics and governance of AI.},
	language = {en},
	urldate = {2021-02-14},
	month = may,
	year = {2020},
}

@misc{fiesler_tech_2019,
	title = {Tech {Ethics} {Curricula}: {A} {Collection} of {Syllabi}},
	shorttitle = {Tech {Ethics} {Curricula}},
	url = {https://cfiesler.medium.com/tech-ethics-curricula-a-collection-of-syllabi-3eedfb76be18},
	abstract = {TL;DR: Here’s the spreadsheet. Now read on for context!},
	language = {en},
	urldate = {2021-02-14},
	journal = {Medium},
	author = {Fiesler, Casey},
	month = nov,
	year = {2019},
}

@article{frey_artificial_2020,
	title = {Artificial {Intelligence} and {Inclusion}: {Formerly} {Gang}-{Involved} {Youth} as {Domain} {Experts} for {Analyzing} {Unstructured} {Twitter} {Data}},
	volume = {38},
	issn = {0894-4393, 1552-8286},
	shorttitle = {Artificial {Intelligence} and {Inclusion}},
	url = {http://journals.sagepub.com/doi/10.1177/0894439318788314},
	doi = {10.1177/0894439318788314},
	abstract = {Mining social media data for studying the human condition has created new and unique challenges. When analyzing social media data from marginalized communities, algorithms lack the ability to accurately interpret off-line context, which may lead to dangerous assumptions about and implications for marginalized communities. To combat this challenge, we hired formerly gang-involved young people as domain experts for contextualizing social media data in order to create inclusive, community-informed algorithms. Utilizing data from the Gang Intervention and Computer Science Project—a comprehensive analysis of Twitter data from gang-involved youth in Chicago—we describe the process of involving formerly gang-involved young people in developing a new part-of-speech tagger and content classifier for a prototype natural language processing system that detects aggression and loss in Twitter data. We argue that involving young people as domain experts leads to more robust understandings of context, including localized language, culture, and events. These insights could change how data scientists approach the development of corpora and algorithms that affect people in marginalized communities and who to involve in that process. We offer a contextually driven interdisciplinary approach between social work and data science that integrates domain insights into the training of qualitative annotators and the production of algorithms for positive social impact.},
	language = {en},
	number = {1},
	urldate = {2021-02-14},
	journal = {Social Science Computer Review},
	author = {Frey, William R. and Patton, Desmond U. and Gaskell, Michael B. and McGregor, Kyle A.},
	month = feb,
	year = {2020},
	pages = {42--56},
}

@misc{wells_ida_justdata,
	title = {Ida B. Wells Just Data Lab},
	url = {https://www.thejustdatalab.com/about-the-lab},
	abstract = {The IDA B. WELLS Just Data Lab brings together students, educators, activists, and artists  to develop a critical and creative approach to data conception, production, and circulation. Our aim is to rethink and retool data for justice.},
	language = {en-US},
	urldate = {2021-02-14},
	journal = {IDA B. WELLS JUST DATA Lab},
}

@misc{knowles_ethical_data_science_reader_2019,
	title = {jknowles/ethical\_data\_science\_reader},
	url = {https://github.com/jknowles/ethical_data_science_reader},
	abstract = {Readings in the ethics of doing data science. . Contribute to jknowles/ethical\_data\_science\_reader development by creating an account on GitHub.},
  author = {Knowles, Jared},
	language = {en},
	urldate = {2021-02-14},
  year = {2019},
	journal = {GitHub},
}

@misc{benjamin_resources,
	title = {Resources},
	url = {https://www.ruhabenjamin.com/resources},
  author = {Benjamin, Ruha},
	abstract = {A curated list of Tech and Social Justice Initiatives; Fairness, Accountability, and Transparency Initiatives; and Institutes and Centers dedicated to researching and studying technology.},
	language = {en-US},
	urldate = {2021-02-14},
	journal = {Ruha Benjamin},
}

@misc{chris_wiggins_history_2019,
	type = {Education},
	title = {history and ethics of data},
	url = {https://www.slideshare.net/chrishwiggins/history-and-ethics-of-data},
	abstract = {Talk delivered 2019-06-25 as part of the Summer Institute in Computational Social Science,  held at Princeton University https://compsocialscience.github.io/summer-institute/2019/

Video: https://www.youtube.com/watch?v=0suLWheVji0


title:
what should future statisticians, CEO, and senators know about the
history and ethics of data?

abstract:

What should our future statisticians, senators, and CEOs know about the history and ethics of data?
How might understanding that history provide tools and resources to future citizens navigating a future shaped by data empowered algorithms?
I'll present content from a class co-developed over the past several years with Professor Matt Jones of Columbia's Department of History, based on material absent from both the curriculum for future technologists as well as for future humanists.
The intellectual arc traces from the 18th century to present day, beginning with examples of contemporary technological advances, disquieting ethical debates, and financial success powered by panoptic persuasion architectures.},
	urldate = {2021-02-14},
	collaborator = {{chris wiggins}},
	month = jun,
	year = {2019},
}

@article{zook_ten_2017,
	title = {Ten simple rules for responsible big data research},
	volume = {13},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005399},
	doi = {10.1371/journal.pcbi.1005399},
	language = {en},
	number = {3},
	urldate = {2021-02-14},
	journal = {PLOS Computational Biology},
	author = {Zook, Matthew and Barocas, Solon and Boyd, Danah and Crawford, Kate and Keller, Emily and Gangadharan, Seeta Peña and Goodman, Alyssa and Hollander, Rachelle and Koenig, Barbara A. and Metcalf, Jacob and Narayanan, Arvind and Nelson, Alondra and Pasquale, Frank},
	month = mar,
	year = {2017},
	keywords = {Research ethics, Social media, Research design, Medicine and health sciences, Scientists, Cloud computing, Data mining, Research and analysis methods},
	pages = {e1005399},
}


@misc{hao_can_2019,
	title = {Can you make {AI} fairer than a judge? {Play} our courtroom algorithm game},
	shorttitle = {Can you make {AI} fairer than a judge?},
	url = {https://www.technologyreview.com/2019/10/17/75285/ai-fairer-than-judge-criminal-risk-assessment-algorithm/},
  author = {Hao, Karen and Stray, Jonathan},
	abstract = {As a child, you develop a sense of what “fairness” means. It’s a concept that you learn early on as you come to terms with the world around you. Something either feels fair or it doesn’t. But increasingly, algorithms have begun to arbitrate fairness for us. They decide who sees housing ads, who gets hired…},
	language = {en},
	urldate = {2021-02-15},
  date = {2019-08-17},
	journal = {MIT Technology Review},
}
@Article{Baack_2015,
  author       = {Baack, Stefan},
  title        = {Datafication and empowerment: How the open data movement
                  re-articulates notions of democracy, participation, and
                  journalism},
  year         = 2015,
  volume       = 2,
  number       = 2,
  month        = {Jul},
  pages        = 205395171559463,
  issn         = {2053-9517},
  doi          = {10.1177/2053951715594634},
  url          = {http://dx.doi.org/10.1177/2053951715594634},
  journal      = {Big Data & Society},
  publisher    = {SAGE Publications}
}

@book{o2016weapons,
  title={Weapons of math destruction: How big data increases inequality and threatens democracy},
  author={O'neil, Cathy},
  year={2016},
  publisher={Crown}
}

@book{eubanks2018automating,
  title={Automating inequality: How high-tech tools profile, police, and punish the poor},
  author={Eubanks, Virginia},
  year={2018},
  publisher={St. Martin's Press}
}
@book{noble2018algorithms,
  title={Algorithms of oppression: How search engines reinforce racism},
  author={Noble, Safiya Umoja},
  year={2018},
  publisher={nyu Press}
}

@book{broussard2019artificial,
  title={Artificial Unintelligence: How Computers Misunderstand the World},
  author={Broussard, M.},
  isbn={9780262537018},
  lccn={2017041363},
  series={Mit Press},
  url={https://books.google.com/books?id=4r34DwAAQBAJ},
  year={2019},
  publisher={MIT Press}
}

@book{benjamin2019race,
  title={Race After Technology: Abolitionist Tools for the New Jim Code},
  author={Benjamin, R.},
  isbn={9781509526437},
  lccn={2019015243},
  url={https://books.google.com/books?id=G6-hDwAAQBAJ},
  year={2019},
  publisher={Wiley}
}

@book{loukides2018ethics,
  title={Ethics and Data Science},
  author={Loukides, M. and Mason, H. and Patil, D.},
  isbn={9781492078227},
  url={https://books.google.com/books?id=UXHKDwAAQBAJ},
  year={2018},
  publisher={O'Reilly Media}
}

@book{brown2017emergent,
  title={Emergent Strategy: Shaping Change, Changing Worlds},
  author={brown, adrienne maree},
  isbn={9781849352611},
  series={Emergent Strategy},
  url={https://books.google.com/books?id=JBwwDwAAQBAJ},
  year={2017},
  publisher={AK Press}
}

@misc{hutson_who_nodate,
	title = {Who {Should} {Stop} {Unethical} {A}.{I}.?},
	url = {https://www.newyorker.com/tech/annals-of-technology/who-should-stop-unethical-ai},
	abstract = {At artificial-intelligence conferences, researchers are increasingly alarmed by what they see.},
	language = {en-us},
	urldate = {2021-02-21},
	journal = {The New Yorker},
	author = {Hutson, Matthew},
}
@Article{Franzke_2021,
  author       = {Franzke, Aline Shakti and Muis, Iris and Schäfer, Mirko
                  Tobias},
  title        = {Data Ethics Decision Aid (DEDA): a dialogical framework for
                  ethical inquiry of AI and data projects in the Netherlands},
  year         = 2021,
  month        = {Jan},
  issn         = {1572-8439},
  doi          = {10.1007/s10676-020-09577-5},
  url          = {http://dx.doi.org/10.1007/s10676-020-09577-5},
  journal      = {Ethics and Information Technology},
  publisher    = {Springer Science and Business Media LLC}
}
@article{anderson2008end,
  title={The end of theory: The data deluge makes the scientific method obsolete},
  author={Anderson, Chris},
  journal={Wired magazine},
  volume={16},
  number={7},
  pages={16--07},
  year={2008}
}
@article{mazzocchi2015could,
  title={Could Big Data be the end of theory in science? A few remarks on the epistemology of data-driven science},
  author={Mazzocchi, Fulvio},
  journal={EMBO reports},
  volume={16},
  number={10},
  pages={1250--1255},
  year={2015}
}

@misc{park_data_2021,
	title = {Data {Privacy} in {Higher} {Education}: {Yes}, {Students} {Care}},
  author={Park, Jasmine and Vance, Amelia},
	shorttitle = {Data {Privacy} in {Higher} {Education}},
	url = {https://er.educause.edu/articles/2021/2/data-privacy-in-higher-education-yes-students-care},
	abstract = {Many in higher education believe that students who have grown up using digital technologies (“digital natives”) have little concern for the privacy of},
	language = {en},
	urldate = {2021-02-22},
}


@article{zook_ten_2017,
	title = {Ten simple rules for responsible big data research},
	volume = {13},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1005399},
	doi = {10.1371/journal.pcbi.1005399},
	language = {en},
	number = {3},
	urldate = {2019-03-03},
	journal = {PLOS Computational Biology},
	author = {Zook, Matthew and Barocas, Solon and boyd, danah and Crawford, Kate and Keller, Emily and Gangadharan, Seeta Peña and Goodman, Alyssa and Hollander, Rachelle and Koenig, Barbara A. and Metcalf, Jacob and Narayanan, Arvind and Nelson, Alondra and Pasquale, Frank},
	editor = {Lewitter, Fran},
	month = mar,
	year = {2017},
	pages = {e1005399},
	file = {Full Text:/Users/abeltilahun/Zotero/storage/4YTFHAIV/Zook et al. - 2017 - Ten simple rules for responsible big data research.pdf:application/pdf}
}

@misc{noauthor_ida_nodate,
	title = {{IDA} {B}. {WELLS} {JUST} {DATA} {Lab}},
	url = {https://www.thejustdatalab.com/about-the-lab},
	abstract = {The IDA B. WELLS Just Data Lab brings together students, educators, activists, and artists  to develop a critical and creative approach to data conception, production, and circulation. Our aim is to rethink and retool data for justice.},
	language = {en-US},
	urldate = {2020-12-30},
	journal = {IDA B. WELLS JUST DATA Lab},
	file = {Snapshot:/Users/abeltilahun/Zotero/storage/UFZ7LBNJ/about-the-lab.html:text/html}
}

@misc{noauthor_resources_nodate,
	title = {Resources},
	url = {https://www.ruhabenjamin.com/resources},
	abstract = {A curated list of Tech and Social Justice Initiatives; Fairness, Accountability, and Transparency Initiatives; and Institutes and Centers dedicated to researching and studying technology.},
	language = {en-US},
	urldate = {2020-12-30},
	journal = {Ruha Benjamin},
	file = {Snapshot:/Users/abeltilahun/Zotero/storage/T5XZB8Q8/resources.html:text/html}
}

@misc{noauthor_teaching_nodate,
	title = {Teaching},
	url = {https://www.ruhabenjamin.com/teaching},
	abstract = {Teaching philosophy, courses, and resources.},
	language = {en-US},
	urldate = {2020-12-30},
	journal = {Ruha Benjamin},
	file = {Snapshot:/Users/abeltilahun/Zotero/storage/7TNVPA7U/teaching.html:text/html}
}

@misc{wiggins_thoughts_2018,
	title = {thoughts on an data ethics sequence of courses},
	author = {Wiggins, Chris},
	month = dec,
	year = {2018},
	file = {_.pdf:/Users/abeltilahun/Zotero/storage/T9DSDYSU/_.pdf:application/pdf}
}

@misc{fiesler_tech_2019,
	title = {Tech {Ethics} {Curricula}: {A} {Collection} of {Syllabi}},
	shorttitle = {Tech {Ethics} {Curricula}},
	url = {https://cfiesler.medium.com/tech-ethics-curricula-a-collection-of-syllabi-3eedfb76be18},
	abstract = {TL;DR: Here’s the spreadsheet. Now read on for context!},
	language = {en},
	urldate = {2021-01-18},
	journal = {Medium},
	author = {Fiesler, Casey},
	month = nov,
	year = {2019},
	file = {Snapshot:/Users/abeltilahun/Zotero/storage/32VXTSQ5/tech-ethics-curricula-a-collection-of-syllabi-3eedfb76be18.html:text/html}
}

@article{frey_artificial_2020,
	title = {Artificial {Intelligence} and {Inclusion}: {Formerly} {Gang}-{Involved} {Youth} as {Domain} {Experts} for {Analyzing} {Unstructured} {Twitter} {Data}},
	volume = {38},
	issn = {0894-4393},
	shorttitle = {Artificial {Intelligence} and {Inclusion}},
	url = {https://doi.org/10.1177/0894439318788314},
	doi = {10.1177/0894439318788314},
	abstract = {Mining social media data for studying the human condition has created new and unique challenges. When analyzing social media data from marginalized communities, algorithms lack the ability to accurately interpret off-line context, which may lead to dangerous assumptions about and implications for marginalized communities. To combat this challenge, we hired formerly gang-involved young people as domain experts for contextualizing social media data in order to create inclusive, community-informed algorithms. Utilizing data from the Gang Intervention and Computer Science Project—a comprehensive analysis of Twitter data from gang-involved youth in Chicago—we describe the process of involving formerly gang-involved young people in developing a new part-of-speech tagger and content classifier for a prototype natural language processing system that detects aggression and loss in Twitter data. We argue that involving young people as domain experts leads to more robust understandings of context, including localized language, culture, and events. These insights could change how data scientists approach the development of corpora and algorithms that affect people in marginalized communities and who to involve in that process. We offer a contextually driven interdisciplinary approach between social work and data science that integrates domain insights into the training of qualitative annotators and the production of algorithms for positive social impact.},
	language = {en},
	number = {1},
	urldate = {2021-01-19},
	journal = {Social Science Computer Review},
	author = {Frey, William R. and Patton, Desmond U. and Gaskell, Michael B. and McGregor, Kyle A.},
	month = feb,
	year = {2020},
	note = {Publisher: SAGE Publications Inc},
	keywords = {ethics, social media, qualitative methods, Big Data, artificial intelligence, domain experts, gang violence, inclusion, law enforcement, natural language processing},
	pages = {42--56}
}

@misc{dignazio_5_2020,
	title = {5 {Questions} on {Data} and {Context} with {Desmond} {Patton}},
	url = {https://medium.com/data-feminism/5-questions-on-data-and-context-with-desmond-patton-5a09661cbbc6},
	abstract = {By Catherine D’Ignazio with editing by Isabel Carter},
	language = {en},
	urldate = {2021-01-19},
	journal = {Medium},
	author = {D'Ignazio, Catherine},
	month = feb,
	year = {2020},
	file = {Snapshot:/Users/abeltilahun/Zotero/storage/95AH78JZ/5-questions-on-data-and-context-with-desmond-patton-5a09661cbbc6.html:text/html}
}

@misc{noauthor_reading_nodate,
	title = {A reading list on {AI} ethics},
	url = {https://caitiewrites.gitbooks.io/ai-ethics-reading-list/content/}
}

@misc{noauthor_ethics_2020,
	title = {Ethics and {Governance} of {AI} {Reading} {List} {\textbar} {Berkman} {Klein} {Center}},
	url = {https://cyber.harvard.edu/ethics-and-governance-ai-reading-list},
	abstract = {{\textless}p dir="ltr"{\textgreater}Our work is designed to catalyze and advance AI in the public interest, with the aim of including a broad set of voices in understanding and addressing the human impacts of AI. The Berkman Klein Center, in collaboration with the MIT Media Lab, serves as a collaborative platform through which stakeholders working across disciplines, sectors, and geographies can meet, engage, learn, and share. This document serves as a curated, evolving list of resources related to the topic of the ethics and governance of AI.},
	language = {en},
	urldate = {2021-02-03},
	month = may,
	year = {2020},
	file = {Snapshot:/Users/abeltilahun/Zotero/storage/K5LEGGH9/ethics-and-governance-ai-reading-list.html:text/html}
}

@misc{noauthor_readings_2019,
	title = {Readings in {Ethical} {Data} {Science}: {An} {Incomplete} {Annotated} {Reading} {List}},
	publisher = {Civilytics Consulting LLC},
	month = jul,
	year = {2019},
	file = {b2a99-ethicalandinclusivedatasciencereadings.pdf:/Users/abeltilahun/Zotero/storage/DPVBEJA9/b2a99-ethicalandinclusivedatasciencereadings.pdf:application/pdf}
}

@misc{noauthor_bookclub_nodate,
	title = {Bookclub on {Data} {Science} {Ethics} · {Teach} {Data} {Science}},
	url = {https://teachdatascience.com/bookclub/},
	urldate = {2021-02-03},
	journal = {Teach Data Science},
	file = {Snapshot:/Users/abeltilahun/Zotero/storage/FCUS5GGQ/bookclub.html:text/html}
}

@misc{dunn_tech_nodate,
	title = {Tech for good isn't a thing},
	url = {https://relay.substack.com/p/tech-for-good-isnt-a-thing},
	abstract = {Because 'tech for bad' isn't a thing either},
	urldate = {2021-02-03},
	author = {Dunn, Alix}
}

@misc{noauthor_teaching_nodate-1,
	title = {Teaching with {Panopto}},
	url = {https://ctl.columbia.edu/resources-and-technology/teaching-with-technology/teaching-online/panopto/},
	urldate = {2021-02-11}
}

@misc{noauthor_video_2020,
	title = {Video {Production} {Best} {Practices}},
	url = {https://ctl.columbia.edu/resources-and-technology/teaching-with-technology/teaching-online/video-best-practices/},
	abstract = {Visit the post for more.},
	language = {en-US},
	urldate = {2021-02-11},
	journal = {Columbia CTL},
	month = apr,
	year = {2020}
}

@misc{noauthor_kristian_nodate,
	title = {Kristian {Lum}},
	url = {https://www.widsconference.org/kristian_lum.html},
	abstract = {Kristian Lum, a statistician and research assistant professor at the University of Pennsylvania, describes how following her interests has led her on an everchanging career path across business, public service, and academia.},
	language = {en},
	urldate = {2021-02-11},
	journal = {Women in Data Science (WiDS) Conference},
	file = {Snapshot:/Users/abeltilahun/Zotero/storage/8E5D2D7W/kristian_lum.html:text/html}
}

@article{franzke_data_2021,
	title = {Data {Ethics} {Decision} {Aid} ({DEDA}): a dialogical framework for ethical inquiry of {AI} and data projects in the {Netherlands}},
	issn = {1572-8439},
	shorttitle = {Data {Ethics} {Decision} {Aid} ({DEDA})},
	url = {https://doi.org/10.1007/s10676-020-09577-5},
	doi = {10.1007/s10676-020-09577-5},
	abstract = {This contribution discusses the development of the Data Ethics Decision Aid (DEDA), a framework for reviewing government data projects that considers their social impact, the embedded values and the government’s responsibilities in times of data-driven public management. Drawing from distinct qualitative research approaches, the DEDA framework was developed in an iterative process (2016–2018) and has since then been applied by various Dutch municipalities, the Association of Dutch Municipalities, and the Ministry of General Affairs (NL). We present the DEDA framework as an effective process to moderate case-deliberation and advance the development of responsible data practices. In addition, by thoroughly documenting the deliberation process, the DEDA framework establishes accountability. First, this paper sheds light on the necessity for data ethical case deliberation. Second, it describes the prototypes, the final design of the framework, and its evaluation. After a comparison with other frameworks, and a discussion of the findings, the paper concludes by arguing that the DEDA framework is a useful process for ethical evaluation of data projects for public management and an effective tool for creating awareness of ethical issues in data practices.},
	language = {en},
	urldate = {2021-02-16},
	journal = {Ethics and Information Technology},
	author = {Franzke, Aline Shakti and Muis, Iris and Schäfer, Mirko Tobias},
	month = jan,
	year = {2021},
	file = {Springer Full Text PDF:/Users/abeltilahun/Zotero/storage/67JL3PPK/Franzke et al. - 2021 - Data Ethics Decision Aid (DEDA) a dialogical fram.pdf:application/pdf}
}

@misc{noauthor_data_nodate,
	title = {Data {Ethics} {Decision} {Aid} ({DEDA})},
	url = {https://dataschool.nl/en/deda/},
	abstract = {DEDA helps data analysts, project managers and policy makers to recognize ethical issues in data projects, data management and data policies. Developed in close cooperation with data analysts from the City of Utrecht, DEDA is a tool-kit facilitating initial brainstorming sessions to map ethical issues in data projects, documenting the deliberation process and furthering accountability...},
	language = {en-US},
	urldate = {2021-02-16},
	journal = {Utrecht Data School},
	file = {Snapshot:/Users/abeltilahun/Zotero/storage/9FLWFFPQ/deda.html:text/html}
}

@misc{hutson_who_nodate,
	title = {Who {Should} {Stop} {Unethical} {A}.{I}.?},
	url = {https://www.newyorker.com/tech/annals-of-technology/who-should-stop-unethical-ai},
	abstract = {At artificial-intelligence conferences, researchers are increasingly alarmed by what they see.},
	language = {en-us},
	urldate = {2021-02-17},
	journal = {The New Yorker},
	author = {Hutson, Matthew}
}

@misc{noauthor_about_nodate,
	title = {About {Us} – {The} {Markup}},
	url = {https://themarkup.org/about},
	abstract = {Data-driven investigations of tech and how it influences society},
	language = {en},
	urldate = {2021-02-23},
	file = {Snapshot:/Users/abeltilahun/Zotero/storage/34R2T9FF/about.html:text/html}
}

@misc{noauthor_big_nodate,
	title = {big data ethics},
	url = {https://www.wikidata.org/wiki/Q45029591},
	abstract = {ethics of mass data analytics},
	language = {en},
	urldate = {2021-02-24},
	file = {Snapshot:/Users/abeltilahun/Zotero/storage/35S6KVVA/Q45029591.html:text/html}
}

@article{lipworth_ethics_2017,
	title = {Ethics and {Epistemology} of {Big} {Data}.},
	volume = {14},
	doi = {10.1007/S11673-017-9815-8},
	number = {4},
	journal = {Journal of Bioethical Inquiry},
	author = {Lipworth, Wendy and Mason, Paul H. and Kerridge, Ian},
	month = nov,
	year = {2017},
	keywords = {big data, big data ethics, data ethics},
	pages = {485--488}
}

@misc{schwab_this_2021,
	title = {‘{This} is bigger than just {Timnit}’: {How} {Google} tried to silence a critic and ignited a movement},
	shorttitle = {‘{This} is bigger than just {Timnit}’},
	url = {https://www.fastcompany.com/90608471/timnit-gebru-google-ai-ethics-equitable-tech-movement},
	abstract = {Big Tech has used its power to control the field of AI ethics and avoid accountability. Now, the ouster of Timnit Gebru is putting the movement for equitable tech in the spotlight.},
	language = {en-US},
	urldate = {2021-03-01},
	journal = {Fast Company},
	author = {Schwab, Katharine and Schwab, Katharine and Schwab, Katharine},
	month = feb,
	year = {2021},
	file = {Snapshot:/Users/abeltilahun/Zotero/storage/SJSESCE6/timnit-gebru-google-ai-ethics-equitable-tech-movement.html:text/html}
}

@book{hayes_phrenology_2019,
	title = {Phrenology: {A} cautionary tale for {Data} {Science} and how ethics can help},
	shorttitle = {Phrenology},
	abstract = {Phrenology, from "phren" meaning "mind" and "logos" meaning knowledge, was the study of the shapes and contours of the skull as indicative of human mental faculties and character traits. It was developed initially by Franz Joseph Gall (1758-1828) and grew to an internationally recognized science and practice throughout the 19th-century. Although it was a popular into the 20th Century and was still generating scientific research into 21st century, it has been wholly debunked. So what does a discredited 19th century pseudoscience have to do with Data Science, which is simultaneously the sexiest job of the 21st century and a scientific paradigm shift? Maybe not much on the surface, but when one considers the methods of and the ways in which phrenology was applied, some eerie echoes reverberate across time. So what did phrenologists do? They measured and read the size of and contours on people's heads and used these measurements to infer certain aspects of individual personality, character, and behaviors. For well over 100 years, the "science of phrenology" was a well regarded as any attempt to understand human behavior. Using anatomy and brain structure to understand personality and behavior had a great amount of face validity, especially when it could be supported by scientific measurement.},
	author = {Hayes, Sherrill},
	month = jan,
	year = {2019},
	file = {Full Text PDF:/Users/abeltilahun/Zotero/storage/VRQBMXFY/Hayes - 2019 - Phrenology A cautionary tale for Data Science and.pdf:application/pdf}
}

@article{kwet_digital_2019,
	title = {Digital colonialism: {US} empire and the new imperialism in the {Global} {South}},
	volume = {60},
	issn = {0306-3968},
	shorttitle = {Digital colonialism},
	url = {https://doi.org/10.1177/0306396818823172},
	doi = {10.1177/0306396818823172},
	abstract = {This article proposes a conceptual framework of how the United States is reinventing colonialism in the Global South through the domination of digital technology. Using South Africa as a case study, it argues that US multinationals exercise imperial control at the architecture level of the digital ecosystem: software, hardware and network connectivity, which then gives rise to related forms of domination. The monopoly power of multinational corporations is used for resource extraction through rent and surveillance – economic domination. By controlling the digital ecosystem, Big Tech corporations control computer-mediated experiences, giving them direct power over political, economic and cultural domains of life – imperial control. The centrepiece of surveillance capitalism, Big Data, violates the sanctity of privacy and concentrates economic power in the hands of US corporations – a system of global surveillance capitalism. As a feature of surveillance capitalism, Global North intelligence agencies partner with their own corporations to conduct mass and targeted surveillance in the Global South – which intensifies imperial state surveillance. US elites have persuaded people that society must proceed according to its ruling class conceptions of the digital world, setting the foundation for tech hegemony. The author argues for a different ecosystem that decentralises technology by placing control directly into the hands of the people to counter the rapidly advancing frontier of digital empire.},
	language = {en},
	number = {4},
	urldate = {2021-03-01},
	journal = {Race \& Class},
	author = {Kwet, Michael},
	month = apr,
	year = {2019},
	note = {Publisher: SAGE Publications Ltd},
	keywords = {South Africa, Big Data, Big Tech, digital colonialism, digital ecosystem, global surveillance capitalism, tech hegemony, US multinationals},
	pages = {3--26}
}

@inproceedings{henderson_teaching_2019,
	address = {New York, NY, USA},
	series = {{CEP} '19},
	title = {Teaching {Data} {Ethics}: {We}'re going to ethics the heck out of this},
	isbn = {978-1-4503-6631-1},
	shorttitle = {Teaching {Data} {Ethics}},
	url = {https://doi.org/10.1145/3294016.3294017},
	doi = {10.1145/3294016.3294017},
	abstract = {This paper outlines a new Data Ethics \& Privacy module that was introduced to computer science students in 2018. The module aims to raise student awareness of current debates in computer science such as bias in artificial intelligence, algorithmic accountability, filter bubbles and data protection, and practical mechanisms for addressing these issues. To do this, the module includes interdisciplinary content from ethics, law and computer science, and also adopts some teaching methods from the law. I describe the format of the module, challenges with module design and approval, some initial comments on the first year's cohort, and plans for future improvements. I believe that the topic is currently important and this discussion might be of interest to other computer science departments considering the introduction of similar content.},
	urldate = {2021-03-15},
	booktitle = {Proceedings of the 3rd {Conference} on {Computing} {Education} {Practice}},
	publisher = {Association for Computing Machinery},
	author = {Henderson, Tristan},
	month = jan,
	year = {2019},
	keywords = {algorithmic accountability, data ethics, education},
	pages = {1--4},
	file = {Full Text PDF:/Users/abeltilahun/Zotero/storage/T8KW6DHM/Henderson - 2019 - Teaching Data Ethics We're going to ethics the he.pdf:application/pdf}
}

@inproceedings{shapiro_re-shape_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Re-{Shape}: {A} {Method} to {Teach} {Data} {Ethics} for {Data} {Science} {Education}},
	isbn = {978-1-4503-6708-0},
	shorttitle = {Re-{Shape}},
	url = {https://doi.org/10.1145/3313831.3376251},
	doi = {10.1145/3313831.3376251},
	abstract = {Data has become central to the technologies and services that human-computer interaction (HCI) designers make, and the ethical use of data in and through these technologies should be given critical attention throughout the design process. However, there is little research on ethics education in computer science that explicitly addresses data ethics. We present and analyze Re-Shape, a method to teach students about the ethical implications of data collection and use. Re-Shape, as part of an educational environment, builds upon the idea of cultivating care and allows students to collect, process, and visualize their physical movement data in ways that support critical reflection and coordinated classroom activities about data, data privacy, and human-centered systems for data science. We also use a case study of Re-Shape in an undergraduate computer science course to explore prospects and limitations of instructional designs and educational technology such as Re-Shape that leverage personal data to teach data ethics.},
	urldate = {2021-03-15},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Shapiro, Ben Rydal and Meng, Amanda and O'Donnell, Cody and Lou, Charlotte and Zhao, Edwin and Dankwa, Bianca and Hostetler, Andrew},
	month = apr,
	year = {2020},
	keywords = {care ethics, computer science education, data ethics, data literacy, data privacy, data science education, information visualization, interaction geography slicer, re-shape},
	pages = {1--13},
	file = {Full Text PDF:/Users/abeltilahun/Zotero/storage/V3976TT6/Shapiro et al. - 2020 - Re-Shape A Method to Teach Data Ethics for Data S.pdf:application/pdf}
}

@article{spradling_ethics_2008,
	title = {Ethics training and decision-making: do computer science programs need help?},
	volume = {40},
	issn = {0097-8418},
	shorttitle = {Ethics training and decision-making},
	url = {https://doi.org/10.1145/1352322.1352188},
	doi = {10.1145/1352322.1352188},
	abstract = {A national web-based survey using SurveyMonkey.com was administered to 700 undergraduate computer science programs in the United States as part of a stratified random sample of 797 undergraduate computer science programs. The 251 program responses (36\% response rate) regarding social and professional issues (computer ethics) are presented. This article describes the demographics of the respondents, presents results concerning whether programs teach social and professional issues, who teaches, the role of training in these programs, the decision making process as it relates to computer ethics and why some programs are not teaching computer ethics. Additionally, we provide suggestions for computer science programs regarding ethics training and decision-making and we share reasons why schools are not teaching computer ethics.},
	number = {1},
	urldate = {2021-03-15},
	journal = {ACM SIGCSE Bulletin},
	author = {Spradling, Carol and Soh, Leen-Kiat and Ansorge, Charles},
	month = mar,
	year = {2008},
	keywords = {education, ethics, ethics training, survey results},
	pages = {153--157},
	file = {Full Text PDF:/Users/abeltilahun/Zotero/storage/SC57M853/Spradling et al. - 2008 - Ethics training and decision-making do computer s.pdf:application/pdf}
}

@misc{noauthor_ethics_nodate,
	title = {Ethics {Education} in {Context} {\textbar} {Proceedings} of the 49th {ACM} {Technical} {Symposium} on {Computer} {Science} {Education}},
	url = {https://dl-acm-org.ezproxy.cul.columbia.edu/doi/10.1145/3159450.3159573},
	urldate = {2021-03-15},
	file = {Ethics Education in Context | Proceedings of the 49th ACM Technical Symposium on Computer Science Education:/Users/abeltilahun/Zotero/storage/PRT75STK/3159450.html:text/html}
}

@inproceedings{fiesler_what_2020,
	address = {Portland OR USA},
	title = {What {Do} {We} {Teach} {When} {We} {Teach} {Tech} {Ethics}?: {A} {Syllabi} {Analysis}},
	isbn = {978-1-4503-6793-6},
	shorttitle = {What {Do} {We} {Teach} {When} {We} {Teach} {Tech} {Ethics}?},
	url = {https://dl.acm.org/doi/10.1145/3328778.3366825},
	doi = {10.1145/3328778.3366825},
	abstract = {As issues of technology ethics become more pervasive in the media and public discussions, there is increasing interest in what role ethics should play in computing education. Not only are there more standalone ethics classes being offered at universities, but calls for greater integration of ethics across computer science curriculum mean that a growing number of CS instructors may be including ethics as part of their courses. To both describe current trends in computing ethics coursework and to provide guidance for further ethics inclusion in computing, we present an in-depth qualitative analysis of 115 syllabi from university technology ethics courses. Our analysis contributes a snapshot of the content and goals of tech ethics classes, and recommendations for how these might be integrated across a computing curriculum.},
	language = {en},
	urldate = {2021-03-17},
	booktitle = {Proceedings of the 51st {ACM} {Technical} {Symposium} on {Computer} {Science} {Education}},
	publisher = {ACM},
	author = {Fiesler, Casey and Garrett, Natalie and Beard, Nathan},
	month = feb,
	year = {2020},
	pages = {289--295},
}

@misc{noauthor_responsible_nodate,
	title = {Responsible {Computer} {Science} {Challenge}},
	url = {https://foundation.mozilla.org/en/what-we-fund/awards/responsible-computer-science-challenge/},
	abstract = {Funding and resources for bright people and bold ideas working to shape a more human-centered internet.},
	language = {en},
	urldate = {2021-03-17},
	journal = {Mozilla Foundation},
	file = {Snapshot:/Users/abeltilahun/Zotero/storage/TDK2TTTY/responsible-computer-science-challenge.html:text/html}
}

@article{hagendorff_ethics_2020,
	title = {The {Ethics} of {AI} {Ethics}: {An} {Evaluation} of {Guidelines}},
	volume = {30},
	issn = {1572-8641},
	shorttitle = {The {Ethics} of {AI} {Ethics}},
	url = {https://doi.org/10.1007/s11023-020-09517-8},
	doi = {10.1007/s11023-020-09517-8},
	abstract = {Current advances in research, development and application of artificial intelligence (AI) systems have yielded a far-reaching discourse on AI ethics. In consequence, a number of ethics guidelines have been released in recent years. These guidelines comprise normative principles and recommendations aimed to harness the “disruptive” potentials of new AI technologies. Designed as a semi-systematic evaluation, this paper analyzes and compares 22 guidelines, highlighting overlaps but also omissions. As a result, I give a detailed overview of the field of AI ethics. Finally, I also examine to what extent the respective ethical principles and values are implemented in the practice of research, development and application of AI systems—and how the effectiveness in the demands of AI ethics can be improved.},
	language = {en},
	number = {1},
	urldate = {2021-03-17},
	journal = {Minds and Machines},
	author = {Hagendorff, Thilo},
	month = mar,
	year = {2020},
	pages = {99--120},
	file = {Springer Full Text PDF:/Users/abeltilahun/Zotero/storage/M2U25TIQ/Hagendorff - 2020 - The Ethics of AI Ethics An Evaluation of Guidelin.pdf:application/pdf}
}

@article{heder_criticism_2020,
	title = {A criticism of {AI} ethics guidelines},
	volume = {20},
	issn = {2063-4552, 1587-8694},
	url = {https://inftars.infonia.hu/article.php?doi=inftars.XX.2020.4.5},
	doi = {10.22503/inftars.XX.2020.4.5},
	abstract = {This paper investigates the current wave of Artificial Intelligence Ethics GUidelines (AIGUs). The goal is not to provide a broad survey of the details of such efforts; instead, the reasons for the proliferation of such guidelines is investigated. Two main research questions are pursued. First, what is the justification for the proliferation of AIGUs, and what are the reasonable goals and limitations of such projects? Second, what are the specific concerns of AI that are so unique that general technology regulation cannot cover them? The paper reveals that the development of AI guidelines is part of a decades-long trend of an ever-increasing express need for stronger social control of technology, and that many of the concerns of the AIGUs are not specific to the technology itself, but are rather about transparency and human oversight.  Nevertheless, the positive potential of the situation is that the intense world-wide focus on AIGUs will yield such profound guidelines that the regulation of other technologies may want to follow suite.},
	number = {4},
	urldate = {2021-03-17},
	journal = {Információs Társadalom},
	author = {Héder, Mihály},
	month = dec,
	year = {2020},
	pages = {57},
	file = {Full Text:/Users/abeltilahun/Zotero/storage/98V376I5/Héder - 2020 - A criticism of AI ethics guidelines.pdf:application/pdf}
}

@article{zerilli_transparency_2019,
	title = {Transparency in {Algorithmic} and {Human} {Decision}-{Making}: {Is} {There} a {Double} {Standard}?},
	volume = {32},
	issn = {2210-5441},
	shorttitle = {Transparency in {Algorithmic} and {Human} {Decision}-{Making}},
	url = {https://doi.org/10.1007/s13347-018-0330-6},
	doi = {10.1007/s13347-018-0330-6},
	abstract = {We are sceptical of concerns over the opacity of algorithmic decision tools. While transparency and explainability are certainly important desiderata in algorithmic governance, we worry that automated decision-making is being held to an unrealistically high standard, possibly owing to an unrealistically high estimate of the degree of transparency attainable from human decision-makers. In this paper, we review evidence demonstrating that much human decision-making is fraught with transparency problems, show in what respects AI fares little worse or better and argue that at least some regulatory proposals for explainable AI could end up setting the bar higher than is necessary or indeed helpful. The demands of practical reason require the justification of action to be pitched at the level of practical reason. Decision tools that support or supplant practical reasoning should not be expected to aim higher than this. We cast this desideratum in terms of Daniel Dennett’s theory of the “intentional stance” and argue that since the justification of action for human purposes takes the form of intentional stance explanation, the justification of algorithmic decisions should take the same form. In practice, this means that the sorts of explanations for algorithmic decisions that are analogous to intentional stance explanations should be preferred over ones that aim at the architectural innards of a decision tool.},
	language = {en},
	number = {4},
	urldate = {2021-03-17},
	journal = {Philosophy \& Technology},
	author = {Zerilli, John and Knott, Alistair and Maclaurin, James and Gavaghan, Colin},
	month = dec,
	year = {2019},
	pages = {661--683}
}

@article{burton18_how_to_teach_comput_ethic,
  author =       {Emanuelle Burton and Judy Goldsmith and Nicholas Mattei},
  title =        {How To Teach Computer Ethics Through Science Fiction},
  journal =      {Communications of the ACM},
  volume =       61,
  number =       8,
  pages =        {54-64},
  year =         2018,
  doi =          {10.1145/3154485},
  url =          {https://doi.org/10.1145/3154485},
  DATE_ADDED =   {Tue Mar 23 14:53:58 2021},
}

@misc{ng_learning_2021,
	title = {Learning about {AI} with {Google} {Brain} and {Landing} {AI} founder {Andrew} {Ng}},
	url = {https://www.technologyreview.com/2021/03/26/1021258/ai-pioneer-andrew-ng-machine-learning-business/},
	abstract = {AI pioneer Andrew Ng reflects on how companies can use machine learning to transform their operations and solve critical problems.},
	language = {en},
	urldate = {2021-03-30},
	journal = {MIT Technology Review},
}

@article{bolukbasi_man_2016,
	title = {Man is to {Computer} {Programmer} as {Woman} is to {Homemaker}? {Debiasing} {Word} {Embeddings}},
	shorttitle = {Man is to {Computer} {Programmer} as {Woman} is to {Homemaker}?},
	url = {http://arxiv.org/abs/1607.06520},
	abstract = {The blind application of machine learning runs the risk of amplifying biases present in data. Such a danger is facing us with word embedding, a popular framework to represent text data as vectors which has been used in many machine learning and natural language processing tasks. We show that even word embeddings trained on Google News articles exhibit female/male gender stereotypes to a disturbing extent. This raises concerns because their widespread use, as we describe, often tends to amplify these biases. Geometrically, gender bias is first shown to be captured by a direction in the word embedding. Second, gender neutral words are shown to be linearly separable from gender definition words in the word embedding. Using these properties, we provide a methodology for modifying an embedding to remove gender stereotypes, such as the association between between the words receptionist and female, while maintaining desired associations such as between the words queen and female. We define metrics to quantify both direct and indirect gender biases in embeddings, and develop algorithms to "debias" the embedding. Using crowd-worker evaluation as well as standard benchmarks, we empirically demonstrate that our algorithms significantly reduce gender bias in embeddings while preserving the its useful properties such as the ability to cluster related concepts and to solve analogy tasks. The resulting embeddings can be used in applications without amplifying gender bias.},
	urldate = {2021-02-27},
	journal = {arXiv:1607.06520 [cs, stat]},
	author = {Bolukbasi, Tolga and Chang, Kai-Wei and Zou, James and Saligrama, Venkatesh and Kalai, Adam},
	month = jul,
	year = {2016},
	note = {arXiv: 1607.06520},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}
@article{bolukbasi2016quantifying,
  title={Quantifying and reducing stereotypes in word embeddings},
  author={Bolukbasi, Tolga and Chang, Kai-Wei and Zou, James and Saligrama, Venkatesh and Kalai, Adam},
  journal={arXiv preprint arXiv:1606.06121},
  year={2016}
}
@inproceedings{tatman2017gender,
  title={Gender and dialect bias in YouTube’s automatic captions},
  author={Tatman, Rachael},
  booktitle={Proceedings of the First ACL Workshop on Ethics in Natural Language Processing},
  pages={53--59},
  year={2017}
}
@article{prates2019assessing,
  title={Assessing gender bias in machine translation: a case study with google translate},
  author={Prates, Marcelo OR and Avelar, Pedro H and Lamb, Luis C},
  journal={Neural Computing and Applications},
  pages={1--19},
  year={2019},
  publisher={Springer}
}
@article{hutchinson2020social,
  title={Social biases in NLP models as barriers for persons with disabilities},
  author={Hutchinson, Ben and Prabhakaran, Vinodkumar and Denton, Emily and Webster, Kellie and Zhong, Yu and Denuyl, Stephen},
  journal={arXiv preprint arXiv:2005.00813},
  year={2020}
}
@article{abid2021persistent,
  title={Persistent Anti-Muslim Bias in Large Language Models},
  author={Abid, Abubakar and Farooqi, Maheen and Zou, James},
  journal={arXiv preprint arXiv:2101.05783},
  year={2021}
}
@article{nowogrodzki2016mining,
  title={Mining the secrets of college syllabuses},
  author={Nowogrodzki, Anna},
  journal={Nature News},
  volume={539},
  number={7627},
  pages={125},
  year={2016}
}


@techreport{westDiscriminatingSystemsGender2019,
	title = {Discriminating {Systems}: {Gender}, {Race}, and {Power} in {AI}},
	url = {https://ainowinstitute.org/discriminatingsystems.pdf},
	institution = {AI Now Institute},
	author = {West, Sarah Myers and Whittaker, Meredith and Crawford, Kate},
	month = apr,
	year = {2019},
	file = {Discriminating Systems.pdf:files/4940/Discriminating Systems.pdf:application/pdf},
}

@inproceedings{sloaneInequalityNameGame2019a,
	address = {Berlin, Germany},
	title = {Inequality {Is} the {Name} of the {Game}: {Thoughts} on the {Emerging} {Field} of {Technology}, {Ethics} and {Social} {Justice}},
	url = {https://www.ssoar.info/ssoar/handle/document/62583#},
	urldate = {2019-06-05},
	booktitle = {Proceedings of the {Weizenbaum} {Conference} 2019 "{Challenges} of {Digital} {Inequality} - {Digital} {Education}, {Digital} {Work}, {Digital} {Life}"},
	author = {Sloane, Mona},
	year = {2019},
	file = {Inequality Is the Name of the Game\: Thoughts on the Emerging Field of Technology, Ethics and Social Justice:files/4959/62583.html:text/html;ssoar-2019-sloane-Inequality_Is_the_Name_of.pdf:files/4953/ssoar-2019-sloane-Inequality_Is_the_Name_of.pdf:application/pdf},
}

@misc{thomasConversationTechEthics2019,
	type = {fast.ai},
	title = {A {Conversation} about {Tech} {Ethics} with the {New} {York} {Times} {Chief} {Data} {Scientist} · fast.ai},
	url = {https://www.fast.ai/2019/03/04/ethics-framework/},
	urldate = {2019-12-12},
	author = {Thomas, Rachel and Wiggins, Chris},
	month = mar,
	year = {2019},
	file = {A Conversation about Tech Ethics with the New York Times Chief Data Scientist · fast.ai:files/5309/ethics-framework.html:text/html},
}

@unpublished{themoore-sloandatascienceenvironments:newyorkuniversityucberkeleyandtheuniversityofwashingtonCreatingInstitutionalChange2018,
	title = {Creating {Institutional} {Change} in {Data} {Science}},
	url = {http://msdse.org/files/Creating_Institutional_Change.pdf},
	abstract = {Tian gave this to me (read through it on 3/24/20).  Describes Data 8 approach among other initiatives at these three universities},
	author = {The Moore-Sloan Data Science Environments: New York University, UC Berkeley, {and} the University of Washington},
	month = mar,
	year = {2018},
	file = {Creating_Institutional_Change.pdf:files/5369/Creating_Institutional_Change.pdf:application/pdf},
}

@article{lueDataScienceFoundation2019,
	title = {Data {Science} as a {Foundation} for {Inclusive} {Learning}},
	volume = {1},
	issn = {,},
	url = {https://hdsr.mitpress.mit.edu/pub/rye9y1w0},
	doi = {10.1162/99608f92.c9267215},
	abstract = {STEM (science, technology, engineering, and mathematics) fields such as computer science and statistics have traditionally struggled to increase participation from underrepresented groups such as women and minorities. And while progress has been made in developing more inclusive classroom pedagogies and programs, rates of representation have remained low over the past 20 years. The emerging field of data science with its roots in both computer science and statistics faces the same challenges, but also presents a unique opportunity to build a more inclusive framework for the teaching of STEM. The widening application of data science methods to nearly every field imaginable in the natural sciences, social sciences, and humanities opens up avenues for engagement based on what students care about and the challenges they are most interested in tackling. Data science therefore provides an opportunity to build an inclusive STEM curriculum from the ground up that connects with multiple disciplines as well as the personal passions of students.Keywords: education, inclusive teaching, pedagogy, STEM, curriculum, statistics, computer science},
	language = {en},
	number = {2},
	urldate = {2020-03-24},
	journal = {Harvard Data Science Review},
	author = {Lue, Robert A.},
	month = nov,
	year = {2019},
	note = {Publisher: PubPub},
	file = {Full Text PDF:files/5384/Lue - 2019 - Data Science as a Foundation for Inclusive Learnin.pdf:application/pdf;Snapshot:files/5385/rye9y1w0.html:text/html},
}

@article{rawlings-gossKeepingDataScience2018,
	title = {Keeping {Data} {Science} {Broad}: {Negotiating} the {Digital} and {Data} {Divide} {Among} {Higher} {Education} {Institutions}},
	shorttitle = {Keeping {Data} {Science} {Broad}},
	url = {https://scholar.valpo.edu/math_stat_fac_pubs/64},
	journal = {Mathematics and Statistics Faculty Publications},
	author = {Rawlings-Goss, Renata and Cassel, Lillian (Boots) and Cragin, Melissa and Cramer, Catherine and Dingle, Angela and Friday-Stroud, Shawnta and Herron, Al and Horton, Nicholas and Inniss, Tasha and Jordan, Kari and Ordóñez, Patti and Rudis, Mary and Rwebangira, Robert and Schmitt, Karl and Smith, Dale and Stephens, Sonya},
	month = jan,
	year = {2018},
	file = {"Keeping Data Science Broad\: Negotiating the Digital and Data Divide Am" by Renata Rawlings-Goss, Lillian (Boots) Cassel et al.:files/6461/64.html:text/html},
}

@misc{fieslerTechEthicsCurricula2019,
	title = {Tech {Ethics} {Curricula}: {A} {Collection} of {Syllabi}},
	shorttitle = {Tech {Ethics} {Curricula}},
	url = {https://cfiesler.medium.com/tech-ethics-curricula-a-collection-of-syllabi-3eedfb76be18},
	abstract = {TL;DR: Here’s the spreadsheet. Now read on for context!},
	language = {en},
	urldate = {2021-01-18},
	journal = {Medium},
	author = {Fiesler, Casey},
	month = nov,
	year = {2019},
	file = {Snapshot:files/6463/tech-ethics-curricula-a-collection-of-syllabi-3eedfb76be18.html:text/html},
}

@article{zauggCollaboratoryColumbiaAspen2021,
	title = {Collaboratory at {Columbia}: {An} {Aspen} {Grove} of {Data} {Science} {Education}},
	doi = {https://doi.org/10.1162/99608f92.53c4a1b4},
	number = {3.4, Fall 2021},
	journal = {Harvard Data Science Review},
	author = {Zaugg, Isabelle A. and Culligan, Patricia J. and Witten, Richard and Zheng, Tian},
	month = oct,
	year = {2021},
}

@inproceedings{fieslerWhatWeTeach2020,
	address = {Portland OR USA},
	title = {What {Do} {We} {Teach} {When} {We} {Teach} {Tech} {Ethics}?: {A} {Syllabi} {Analysis}},
	isbn = {978-1-4503-6793-6},
	shorttitle = {What {Do} {We} {Teach} {When} {We} {Teach} {Tech} {Ethics}?},
	url = {https://dl.acm.org/doi/10.1145/3328778.3366825},
	doi = {10.1145/3328778.3366825},
	abstract = {As issues of technology ethics become more pervasive in the media and public discussions, there is increasing interest in what role ethics should play in computing education. Not only are there more standalone ethics classes being offered at universities, but calls for greater integration of ethics across computer science curriculum mean that a growing number of CS instructors may be including ethics as part of their courses. To both describe current trends in computing ethics coursework and to provide guidance for further ethics inclusion in computing, we present an in-depth qualitative analysis of 115 syllabi from university technology ethics courses. Our analysis contributes a snapshot of the content and goals of tech ethics classes, and recommendations for how these might be integrated across a computing curriculum.},
	language = {en},
	urldate = {2021-03-17},
	booktitle = {Proceedings of the 51st {ACM} {Technical} {Symposium} on {Computer} {Science} {Education}},
	publisher = {ACM},
	author = {Fiesler, Casey and Garrett, Natalie and Beard, Nathan},
	month = feb,
	year = {2020},
	pages = {289--295},
	file = {Fiesler et al. - 2020 - What Do We Teach When We Teach Tech Ethics A Syl.pdf:files/6582/Fiesler et al. - 2020 - What Do We Teach When We Teach Tech Ethics A Syl.pdf:application/pdf},
}

@misc{nkondeMutaleNkondeAI2021,
	address = {Columbia Data Science Institute},
	title = {Mutale {Nkonde}, {AI} for the {People}},
	shorttitle = {Race + {Data} {Science} {Lecture} {Series}},
	url = {https://www.youtube.com/watch?v=j7XUNWEiBdA&t=1127s},
	abstract = {117 views • Apr 18, 2021 • Hosted on Thursday, April 15, 2021

Guest Speaker: Mutale Nkonde, Founding Director, AI for the People

Chair \&amp; Moderator: Desmond Upton Patton, Associate Director of Diversity, Equity and Inclusion, The Data Science Institute, Columbia University. Patton is also Associate Professor of Social Work; Associate Dean of Curriculum Innovation and Academic Affairs; and Courtesy Appointment in Department of Sociology, Columbia University School of Social Work.

Talk Title: Elections, Online Chatter and Content Moderation

Abstract: The talk centers on the work done by AI for the People on racially targeted disinformation on Twitter during the 2020 Election and the challenges we faced communicating this to trust and safety teams because of their lack of how to read online culture through speech. The talk will introduce listeners to how the environment changed from 2016 to 2020, our findings detailed here and end with recommendations on how to increase the racial literacy of computer scientists working in industry settings.

Bio: Mutale Nkonde is the founding director of AI for the People, a non profit communications firm that uses journalism, arts and culture to advance racial justice in tech. During the 2020 presidential election her team identified a disinformation network targeting Black voters in the Philadelphia news ecosystem, and published the findings in the Harvard Kennedy School’s Misinformation Review, read it here. In 2021 AI for the People launched their biometric justice vertical by producing a film supporting a ban of facial recognition in New York State, in partnership with Amnesty International, watch it here. Nkonde writes widely on racial impacts of advanced technical systems, is a widely sought after media commentator and seeks to create a safe space for Black technologists who feel marginalized within the wider tech sector.

Prior to this she lead a team that introduced the Algorithm and Deepfakes Accountability Acts and the No Biometric Barriers Act to the US House of Representatives in 2019 and started her career as a broadcast journalist before transitioning into the world of tech. She currently sits on the Tik Tok Content Moderation Advisory Board, advises the Center of Media, Technology and Democracy at McGill University and is a key constituent for the UN 3C Table on AI.
      





  
        Show less
      


  
        Show more},
	urldate = {2021-06-03},
	author = {Nkonde, Mutale and Patton, Desmond},
	month = apr,
	year = {2021},
}

@techreport{metcalfPedagogicalApproachesData2015,
	type = {Draft {Version}, {Produced} for {Council} for {Big} {Data}, {Ethics}, and {Society}},
	title = {Pedagogical {Approaches} to {Data} {Ethics}},
	language = {en},
	institution = {Data \& Society Research Institute},
	author = {Metcalf, Jacob and Crawford, Kate and Keller, Emily},
	month = apr,
	year = {2015},
	pages = {16},
	file = {Metcalf et al. - Pedagogical Approaches to Data Ethics.pdf:files/6819/Metcalf et al. - Pedagogical Approaches to Data Ethics.pdf:application/pdf},
}

@inproceedings{rajiYouCanSit2021,
	address = {Virtual Event Canada},
	title = {You {Can}'t {Sit} {With} {Us}: {Exclusionary} {Pedagogy} in {AI} {Ethics} {Education}},
	isbn = {978-1-4503-8309-7},
	shorttitle = {You {Can}'t {Sit} {With} {Us}},
	url = {https://dl.acm.org/doi/10.1145/3442188.3445914},
	doi = {10.1145/3442188.3445914},
	abstract = {Given a growing concern about the lack of ethical consideration in the Artificial Intelligence (AI) field, many have begun to question how dominant approaches to the disciplinary education of computer science (CS)—and its implications for AI—has led to the current “ethics crisis”. However, we claim that the current AI ethics education space relies on a form of “exclusionary pedagogy,” where ethics is distilled for computational approaches, but there is no deeper epistemological engagement with other ways of knowing that would benefit ethical thinking or an acknowledgement of the limitations of uni-vocal computational thinking. This results in indifference, devaluation, and a lack of mutual support between CS and humanistic social science (HSS), elevating the myth of technologists as "ethical unicorns" that can do it all, though their disciplinary tools are ultimately limited. Through an analysis of computer science education literature and a review of college-level course syllabi in AI ethics, we discuss the limitations of the epistemological assumptions and hierarchies of knowledge which dictate current attempts at including ethics education in CS training and explore evidence for the practical mechanisms through which this exclusion occurs. We then propose a shift towards a substantively collaborative, holistic, and ethically generative pedagogy in AI education.},
	language = {en},
	urldate = {2021-07-08},
	booktitle = {Proceedings of the 2021 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Raji, Inioluwa Deborah and Scheuerman, Morgan Klaus and Amironesei, Razvan},
	month = mar,
	year = {2021},
	pages = {515--525},
	file = {Raji et al. - 2021 - You Can't Sit With Us Exclusionary Pedagogy in AI.pdf:files/7034/Raji et al. - 2021 - You Can't Sit With Us Exclusionary Pedagogy in AI.pdf:application/pdf},
}

@article{haoStopTalkingAI2021,
	title = {Stop talking about {AI} ethics. {It}’s time to talk about power.},
	url = {https://www.technologyreview.com/2021/04/23/1023549/kate-crawford-atlas-of-ai-review/},
	abstract = {We need to acknowledge both the politics and the physical impact that AI has on the planet, says scholar Kate Crawford in her new book.},
	language = {en},
	urldate = {2021-07-21},
	journal = {MIT Technology Review},
	author = {Hao, Karen},
	month = apr,
	year = {2021},
	file = {Snapshot:files/7101/kate-crawford-atlas-of-ai-review.html:text/html},
}

@article{zeffiroDataEthicsData2021,
	title = {From {Data} {Ethics} to {Data} {Justice} in/as {Pedagogy} ({Dispatch})},
	volume = {15},
	doi = {10.26522/ssj.v15i3.2546},
	journal = {Studies in Social Justice},
	author = {Zeffiro, Andrea},
	month = may,
	year = {2021},
	pages = {450--457},
	file = {Full Text:files/7105/Zeffiro - 2021 - From Data Ethics to Data Justice inas Pedagogy (D.pdf:application/pdf},
}

@article{taylorWhatDataJustice2017,
	title = {What is data justice? {The} case for connecting digital rights and freedoms globally},
	volume = {4},
	shorttitle = {What is data justice?},
	doi = {10.1177/2053951717736335},
	abstract = {The increasing availability of digital data reflecting economic and human development, and in particular the availability of data emitted as a by-product of people’s use of technological devices and services, has both political and practical implications for the way people are seen and treated by the state and by the private sector. Yet the data revolution is so far primarily a technical one: the power of data to sort, categorise and intervene has not yet been explicitly connected to a social justice agenda by the agencies and authorities involved. Meanwhile, although data-driven discrimination is advancing at a similar pace to data processing technologies, awareness and mechanisms for combating it are not. This paper posits that just as an idea of justice is needed in order to establish the rule of law, an idea of data justice – fairness in the way people are made visible, represented and treated as a result of their production of digital data – is necessary to determine ethical paths through a datafying world. Bringing together the emerging scholarly perspectives on this topic, I propose three pillars as the basis of a notion of international data justice: (in)visibility, (dis)engagement with technology and antidiscrimination. These pillars integrate positive with negative rights and freedoms, and by doing so challenge both the basis of current data protection regulations and the growing assumption that being visible through the data we emit is part of the contemporary social contract.},
	journal = {Big Data \& Society},
	author = {Taylor, Linnet},
	month = dec,
	year = {2017},
	pages = {205395171773633},
	file = {Full Text:files/7111/Taylor - 2017 - What is data justice The case for connecting digi.pdf:application/pdf},
}

@misc{ochigameInventionEthicalAI2019,
	title = {The {Invention} of “{Ethical} {AI}”: {How} {Big} {Tech} {Manipulates} {Academia} to {Avoid} {Regulation}},
	shorttitle = {The {Invention} of “{Ethical} {AI}”},
	url = {https://theintercept.com/2019/12/20/mit-ethical-ai-artificial-intelligence/},
	language = {en-US},
	urldate = {2021-09-30},
	journal = {The Intercept},
	author = {Ochigame, Rodrigo},
	month = dec,
	year = {2019},
	file = {Snapshot:files/7277/mit-ethical-ai-artificial-intelligence.html:text/html},
}

@article{oneilOpinionIvoryTower2017,
	chapter = {Opinion},
	title = {Opinion {\textbar} {The} {Ivory} {Tower} {Can}’t {Keep} {Ignoring} {Tech}},
	issn = {0362-4331},
	url = {https://www.nytimes.com/2017/11/14/opinion/academia-tech-algorithms.html},
	abstract = {Algorithms are shaping our lives. Where’s academia when it comes to helping us make sense of this?},
	language = {en-US},
	urldate = {2021-12-09},
	journal = {The New York Times},
	author = {O’Neil, Cathy},
	month = nov,
	year = {2017},
	keywords = {Artificial Intelligence, Colleges and Universities, Computers and the Internet, Data-Mining and Database Marketing, Education (K-12), Regulation and Deregulation of Industry, Silicon Valley (Calif)},
	file = {Snapshot:files/7467/academia-tech-algorithms.html:text/html},
}

@misc{fieslerTechEthicsCurriculum2017,
	title = {Tech {Ethics} {Curriculum} - {Google} {Sheets}},
	url = {https://docs.google.com/spreadsheets/d/1jWIrA8jHz5fYAW4h9CkUD8gKS5V98PDJDymRf8d9vKI/edit#gid=0},
	urldate = {2021-12-09},
	author = {Fiesler, Casey},
	year = {2017},
	file = {Tech Ethics Curriculum - Google Sheets:files/7469/edit.html:text/html},
}
