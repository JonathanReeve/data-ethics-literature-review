{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\users\\\\alind\\\\appdata\\\\local\\\\programs\\\\python\\\\python39\\\\python.exe'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "So now we have turtle files which describe readings.\n",
    "But that information isn't so complete or accurate.\n",
    "So we need to ask some bibliographic databases online\n",
    "for better information, so that we can enhance our graph.\n",
    "\"\"\"\n",
    "\n",
    "from rdflib.namespace import DC, DCTERMS, FOAF, RDF, OWL\n",
    "from rdflib import Graph\n",
    "from rdflib import URIRef, BNode, Literal\n",
    "from rdflib import Namespace\n",
    "import rdflib\n",
    "import click\n",
    "import sys\n",
    "import requests\n",
    "import logging\n",
    "import json\n",
    "\n",
    "\n",
    "# @click.command()\n",
    "# @click.argument('turtlefile', nargs=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "turtleFile = \"data/coursesAndTexts.ttl\"\n",
    "\n",
    "turtleFile= \"data/coursesAndTexts_edit_2.ttl\"\n",
    "\n",
    "def queryCrossRef(title, author=None):\n",
    "    \"\"\"\n",
    "    Let's look up data from CrossRef. Here's the form we'll create,\n",
    "    from their documentation here: https://github.com/CrossRef/rest-api-doc#resource-components\n",
    "    https://api.crossref.org/works?query.author=richard+feynman\n",
    "    \"\"\"\n",
    "    logging.info(f\"Querying {title} by {author}\")\n",
    "    url = \"https://api.crossref.org/works\"\n",
    "    params = {\"query.bibliographic\": title}\n",
    "    if author:\n",
    "        params['query.author'] = author\n",
    "    resp = requests.get(url, params=params)\n",
    "    if resp.ok:\n",
    "        decoded = json.loads(resp.text)\n",
    "        if 'message' in decoded:\n",
    "            if 'items' in decoded['message']:\n",
    "                print(decoded['message']['items'][0])\n",
    "            else:\n",
    "                logging.error(\"Can't find items.\")\n",
    "        else:\n",
    "            logging.error(\"Can't find the message.\")\n",
    "    else:\n",
    "        logging.error(\"Response not ok. Response: {resp}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/edit-distance/\n",
    "import edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.1 (tags/v3.9.1:1e5d33e, Dec  7 2020, 17:08:21) [MSC v.1927 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# edit distance\n",
    "# https://github.com/JonathanReeve/data-ethics-literature-review/blob/main/turtleize/enhanceBibliography.py\n",
    "\n",
    "def editRatio(textA, textB):\n",
    "    \"\"\"\n",
    "    Computes the ratio of edit distances between two titles,\n",
    "    in order to measure title similarity.\n",
    "    \"\"\"\n",
    "    return nltk.edit_distance(textA, textB) / (len(textA + textB)/2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use title and author to query Arxiv metadata\n",
    "\n",
    "import urllib\n",
    "import feedparser\n",
    "import urllib.request\n",
    "\n",
    "base_url = 'http://export.arxiv.org/api/query?';\n",
    "\n",
    "# my arxiv query fn\n",
    "def queryArxiv(title, author=None):\n",
    "    \n",
    "    stringsplit = title.split()\n",
    "    st= \"\"\n",
    "    for s in stringsplit:\n",
    "        st =st+s+\"+\"\n",
    "    \n",
    "    st = st[:-1]\n",
    "    \n",
    "    # add title to query\n",
    "    query = 'search_query='+st+'&searchtype=title'\n",
    "    \n",
    "    # if there is author, add the author to search with +AND+  plus searchtype=author\n",
    "    if author != None:\n",
    "        # add to query\n",
    "        query = query+'+AND+'\n",
    "        # add author\n",
    "        authorsplit = author.split()\n",
    "        st = \"\"\n",
    "        for s in authorsplit:\n",
    "            st = st+s+\"+\"\n",
    "        st = st[:-1]\n",
    "        query = query+st +'&searchtype=author'\n",
    "        \n",
    "    # query=The+Great+A.I&searchtype=title\n",
    "    urlquery = base_url+query\n",
    "    urlquery.encode('utf-8') # 7/\n",
    "    print(\"url query\", urlquery)\n",
    "    with urllib.request.urlopen(urlquery) as url:\n",
    "        response = url.read()\n",
    "\n",
    "    # parse the response using feedparser\n",
    "    feed = feedparser.parse(response)\n",
    "    \n",
    "    editdists = []\n",
    "    \n",
    "    aids =[]\n",
    "    apublished =[]\n",
    "    atitles=[]\n",
    "    aauthors=[]\n",
    "    aabstracts=[]\n",
    "    \n",
    "    # add to the graph the fields\n",
    "    for entry in feed.entries:\n",
    "        \"\"\"print('arxiv-id: %s' % entry.id.split('/abs/')[-1])\n",
    "        print('Published: %s' % entry.published)\n",
    "        print('Title:  %s' % entry.title)\"\"\"\n",
    "        arxiv_id = entry.id\n",
    "        date = entry.published\n",
    "        atitle = entry.title\n",
    "        author_string = entry.author\n",
    "        abstract = entry.summary\n",
    "        \n",
    "        # calc edit dist\n",
    "        edist = editRatio(title, atitle)\n",
    "        \n",
    "        # add to arrays\n",
    "        editdists.append(edist)\n",
    "        aids.append(arxiv_id)\n",
    "        apublished.append(date)\n",
    "        atitles.append(atitle)\n",
    "        aauthors.append(author_string)\n",
    "        aabstracts.append(abstract)\n",
    "    \n",
    "        #g.add((item, dcterms:title, title))\n",
    "\n",
    "    # determine which article is best\n",
    "    minindex = np.argmin(editdists)\n",
    "    #return\n",
    "    \"\"\"title.encode(\"utf8\")\n",
    "    author_string.encode(\"utf8\")\n",
    "    arxiv_id.encode(\"utf8\")\n",
    "    date.encode(\"utf8\")\n",
    "    abstract.encode(\"utf8\")\"\"\"\n",
    "    #date.replace(\"u'\", \"'\")\n",
    "    rtitle = atitles[minindex]\n",
    "    rauthor_string = aauthors[minindex]\n",
    "    rarxiv_id = aids[minindex]\n",
    "    rabstract = aabstracts[minindex]\n",
    "    \n",
    "    return(rtitle, rauthor_string, rarxiv_id, rabstract)\n",
    "\n",
    " #add data to graph function\n",
    "\n",
    "\n",
    "# choose correct article with edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv-id: 1207.3006v1\n",
      "Published: 2012-07-12T16:04:13Z\n",
      "Title:  Excitation Suppression Due to Interactions Between Microwave-Dressed\n",
      "  Rydberg Atoms\n",
      "arxiv-id: 1207.6921v1\n",
      "Published: 2012-07-30T12:49:45Z\n",
      "Title:  Dimer-atom-atom recombination in the universal four-boson system\n",
      "arxiv-id: 1410.7957v1\n",
      "Published: 2014-10-29T12:48:48Z\n",
      "Title:  Effective oscillator strength distributions of spherically symmetric\n",
      "  atoms for calculating polarizabilities and long-range atom-atom interactions\n",
      "arxiv-id: 1912.12035v1\n",
      "Published: 2019-12-27T09:20:05Z\n",
      "Title:  Evolution of energy and angular distributions of sputtered atoms with\n",
      "  variation of atomic number of single crystal target\n",
      "arxiv-id: 2101.03565v1\n",
      "Published: 2021-01-10T15:18:38Z\n",
      "Title:  Improving Efficiency of Sympathetic Cooling in Atom-Ion and Atom-Atom\n",
      "  Confined Collisions\n",
      "arxiv-id: physics/0505131v1\n",
      "Published: 2005-05-19T12:50:08Z\n",
      "Title:  Long range intermolecular forces in triatomic systems: connecting the\n",
      "  atom-diatom and atom-atom-atom representations\n",
      "arxiv-id: 1010.2425v1\n",
      "Published: 2010-10-10T12:35:27Z\n",
      "Title:  Atoms can be divided into three categories: polar, non-polar and\n",
      "  hydrogen atom\n",
      "arxiv-id: physics/0208067v1\n",
      "Published: 2002-08-17T19:40:16Z\n",
      "Title:  Effective potentials for atom-atom interaction at low temperatures\n",
      "arxiv-id: physics/0604220v1\n",
      "Published: 2006-04-27T17:31:48Z\n",
      "Title:  Analysis of the atom-number correlation function in a few-atom trap\n",
      "arxiv-id: 1202.5328v1\n",
      "Published: 2012-02-23T21:32:29Z\n",
      "Title:  Entanglement of Two Atoms using Rydberg Blockade\n"
     ]
    }
   ],
   "source": [
    "(t1, t2, t3, t4)= queryArxiv('atomic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-88d971a990ce>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-88d971a990ce>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    select ?authorLast ?authorGiven\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Sample queries \n",
    "\n",
    "# https://bibliontology.com/content/article.html\n",
    "\n",
    "# https://rdflib.readthedocs.io/en/stable/rdf_terms.html\n",
    "\n",
    "\"\"\"select ?authorLast ?authorGiven\n",
    "where\"\"\"\n",
    "\n",
    "# question mark where do not know \n",
    "\"\"\"?myText dc:creator ?authorID .\n",
    "?authorID a foaf:person .\n",
    "?authorID givenName .\n",
    "?authorID lastName ?authorLast .\"\"\"\n",
    "\n",
    "authorquery1 = \"\"\"SELECT ?name\n",
    "WHERE {\n",
    "    ?person foaf:name ?name .\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "authorquery = \"\"\"select ?givenName ?surname where{\n",
    " var(id) a foaf:Person .\n",
    "}\"\"\"\n",
    "\n",
    "# draft pull request "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary function to remove non-string symbols\n",
    "def ExtractAlphanumeric(InputString):\n",
    "    from string import ascii_letters, digits\n",
    "    return \"\".join([ch for ch in InputString if ch in (ascii_letters + digits)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://data-ethics.tech/text/4MFTEYZK Transparent, explainable, and accountable AI for None None\n",
      "https://data-ethics.tech/text/4K4B5FLS When the Algorithm Itself is a Racist: Diagnosing Ethical Harm in the Basic Components of Software None None\n",
      "https://data-ethics.tech/text/4KCWRSUW The Great A.I None None\n",
      "https://data-ethics.tech/text/4M5D2C6G The Tangled Story Behind Trump’s False Claims Of Voter Fraud None None\n",
      "orig title Transparent, explainable, and accountable AI for\n",
      "author None\n",
      "True\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"NoneType\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-9d216096b43d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasicConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-9d216096b43d>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# query Author\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0maq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"select ?givenName ?surname where{ \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0maq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maq\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mauthor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[0maq\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0maq\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" a foaf:Person .} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"NoneType\") to str"
     ]
    }
   ],
   "source": [
    "# My main\n",
    "from rdflib import URIRef\n",
    "from rdflib import Literal\n",
    "def main():\n",
    "    g = rdflib.Graph()\n",
    "    g.load(turtleFile, format=\"ttl\")\n",
    "    #    for item in g:\n",
    "    #     print(item)\n",
    "    g.bind('z', 'http://www.zotero.org/namespaces/export#')\n",
    "    g.bind('dcterms', 'http://purl.org/dc/terms/')\n",
    "    g.bind('foaf', 'http://xmlns.com/foaf/0.1/')\n",
    "    # This only works if we have the title and author.\n",
    "    # data = g.query(\"\"\"select distinct ?id ?title ?authorFirst ?authorLast where {\n",
    "    #     ?id a z:UserItem .\n",
    "    #     ?id res:resource ?doc .\n",
    "    #     ?doc dcterms:title ?title .\n",
    "    #     ?doc dcterms:creator ?author .\n",
    "    #     ?author foaf:givenName ?authorFirst .\n",
    "    #     ?author foaf:surname ?authorLast .\n",
    "    # }\"\"\")\n",
    "    # itemID, title, authorFirst, authorLast = list(data)[0]\n",
    "    # print(title, authorFirst, authorLast)\n",
    "    # This will work even if we don't have an author\n",
    "    data = g.query(\"\"\"select distinct ?id ?title ?authorFirst ?authorLast where {\n",
    "        ?id a z:UserItem .\n",
    "        ?id res:resource ?doc .\n",
    "        ?doc dcterms:title ?title .\n",
    "        OPTIONAL {\n",
    "          ?doc dcterms:creator ?author .\n",
    "          ?author foaf:givenName ?authorFirst .\n",
    "          ?author foaf:surname ?authorLast .\n",
    "        }\n",
    "    }\"\"\")\n",
    "    resultsDict = {}\n",
    "    for result in data:\n",
    "        itemID, title, authorFirst, authorLast = result\n",
    "        print(itemID, title, authorFirst, authorLast)\n",
    "        if authorFirst is not None and authorLast is not None:\n",
    "            author = f\"{authorFirst} {authorLast}\"\n",
    "        else:\n",
    "            author = None\n",
    "        itemID = str(itemID)\n",
    "        if itemID in resultsDict:\n",
    "            continue # Only take the first one for each ID\n",
    "        else:\n",
    "            resultsDict[itemID] = (title, author)\n",
    "    for itemID, titleAuthor in resultsDict.items():\n",
    "        title, author = titleAuthor\n",
    "        print(\"orig title\", title)\n",
    "        # replace with my function\n",
    "        ss = title.split()\n",
    "        newstring=\"\"\n",
    "        for st in ss:\n",
    "            st1 = ExtractAlphanumeric(st)\n",
    "            newstring=newstring+st1+\" \"\n",
    "        newstring=newstring[:-1]\n",
    "        \n",
    "        \n",
    "        (t1, t2, t3, t4) = queryArxiv(newstring)# title, author, arxiv id, abstract\n",
    "        \n",
    "        if author != None:\n",
    "            # query Author \n",
    "            aq = \"select ?givenName ?surname where{ \"\n",
    "            aq = aq + author\n",
    "            aq =aq + \" a foaf:Person .} \"\n",
    "            \n",
    "            qauthor = g.query(aq)\n",
    "        \n",
    "            print(\"qauthor \", quathor)\n",
    "            (t1, t2, t3, t4) = queryArxiv(newstring, qauthor)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"item id is\", itemID)\n",
    "        # url to rdflib term : wrap in rdf (rdflib documentation)\n",
    "        uitemID = URIRef(itemID)\n",
    "        \n",
    "        print(\"best title:\", t1)\n",
    "        print(\"best author:\", t2) # dc terms creator\n",
    "        #g.add((uitemID, \"dcterms:title\", t1))\n",
    "        #g.add((uitemID, \"dcterms:abstract\", t4))\n",
    "        g.add((uitemID, URIRef('http://purl.org/dc/terms/title'), Literal(t1))) #URIRef(t1)))\n",
    "        g.add((uitemID, URIRef('http://purl.org/dc/terms/creator'), Literal(t2)))\n",
    "        g.add((uitemID, URIRef('http://purl.org/dc/terms/abstract'), Literal(t4))) # URIRef(t4)))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    " #test alphanumeric\n",
    "ss = string.split()\n",
    "newstring=\"\"\n",
    "for st in ss:\n",
    "    st1 = ExtractAlphanumeric(st)\n",
    "    newstring=newstring+st1+\" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write graph to output file\n",
    "g.serialize(destination='output.txt', format='turtle')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
