<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns:res="http://purl.org/vocab/resourcelist/schema#"
 xmlns:z="http://www.zotero.org/namespaces/export#"
 xmlns:ctag="http://commontag.org/ns#"
 xmlns:dcterms="http://purl.org/dc/terms/"
 xmlns:bibo="http://purl.org/ontology/bibo/"
 xmlns:foaf="http://xmlns.com/foaf/0.1/">
    <z:UserItem rdf:about="5L4FS7PR">
        <res:resource rdf:resource="http://arxiv.org/abs/1412.3756"/>
        <z:repository>arXiv.org</z:repository>
        <z:accessDate>2021-05-09 03:53:26</z:accessDate>
        <ctag:tagged>
            <ctag:AutoTag>
               <ctag:label>Statistics - Machine Learning</ctag:label>
            </ctag:AutoTag>
        </ctag:tagged>
        <ctag:tagged>
            <ctag:AutoTag>
               <ctag:label>Computer Science - Computers and Society</ctag:label>
            </ctag:AutoTag>
        </ctag:tagged>
    </z:UserItem>
    <bibo:AcademicArticle rdf:about="http://arxiv.org/abs/1412.3756">
        <dcterms:creator rdf:nodeID="n9724"/>
        <dcterms:title>Certifying and removing disparate impact</dcterms:title>
        <bibo:uri>http://arxiv.org/abs/1412.3756</bibo:uri>
        <z:extra>arXiv: 1412.3756</z:extra>
        <dcterms:creator rdf:nodeID="n9722"/>
        <bibo:authorList>
            <rdf:Seq>
                <rdf:li rdf:nodeID="n9722"/>
                <rdf:li rdf:nodeID="n9724"/>
                <rdf:li rdf:nodeID="n9725"/>
                <rdf:li rdf:nodeID="n9726"/>
                <rdf:li rdf:nodeID="n9727"/>
            </rdf:Seq>
        </bibo:authorList>
        <dcterms:abstract>What does it mean for an algorithm to be biased? In U.S. law, unintentional bias is encoded via disparate impact, which occurs when a selection process has widely different outcomes for different groups, even as it appears to be neutral. This legal determination hinges on a definition of a protected class (ethnicity, gender, religious practice) and an explicit description of the process. When the process is implemented using computers, determining disparate impact (and hence bias) is harder. It might not be possible to disclose the process. In addition, even if the process is open, it might be hard to elucidate in a legal setting how the algorithm makes its decisions. Instead of requiring access to the algorithm, we propose making inferences based on the data the algorithm uses. We make four contributions to this problem. First, we link the legal notion of disparate impact to a measure of classification accuracy that while known, has received relatively little attention. Second, we propose a test for disparate impact based on analyzing the information leakage of the protected class from the other data attributes. Third, we describe methods by which data might be made unbiased. Finally, we present empirical evidence supporting the effectiveness of our test for disparate impact and our approach for both masking bias and preserving relevant information in the data. Interestingly, our approach resembles some actual selection practices that have recently received legal scrutiny.</dcterms:abstract>
        <dcterms:creator rdf:nodeID="n9725"/>
        <dcterms:creator rdf:nodeID="n9726"/>
        <dcterms:creator rdf:nodeID="n9727"/>
        <dcterms:isPartOf>
            <bibo:Issue>
                <dcterms:date>2015-07-15</dcterms:date>
                <dcterms:isPartOf>
                    <bibo:Journal>
                       <dcterms:title>arXiv:1412.3756 [cs, stat]</dcterms:title>
                    </bibo:Journal>
                </dcterms:isPartOf>
            </bibo:Issue>
        </dcterms:isPartOf>
    </bibo:AcademicArticle>
    <foaf:Person rdf:nodeID="n9722">
        <foaf:givenName>Michael</foaf:givenName>
        <foaf:surname>Feldman</foaf:surname>
    </foaf:Person>
    <foaf:Person rdf:nodeID="n9724">
        <foaf:givenName>Sorelle</foaf:givenName>
        <foaf:surname>Friedler</foaf:surname>
    </foaf:Person>
    <foaf:Person rdf:nodeID="n9725">
       <foaf:givenName>John</foaf:givenName><foaf:surname>Moeller</foaf:surname>
    </foaf:Person>
    <foaf:Person rdf:nodeID="n9726">
        <foaf:givenName>Carlos</foaf:givenName>
        <foaf:surname>Scheidegger</foaf:surname>
    </foaf:Person>
    <foaf:Person rdf:nodeID="n9727">
        <foaf:givenName>Suresh</foaf:givenName>
        <foaf:surname>Venkatasubramanian</foaf:surname>
    </foaf:Person>
    <z:UserItem rdf:about="#item_2">
        <res:resource>
            <bibo:Note>
                <z:note>Comment: Extended version of paper accepted at 2015 ACM SIGKDD Conference on Knowledge Discovery and Data Mining</z:note>
            </bibo:Note>
        </res:resource>
    </z:UserItem>
</rdf:RDF>
