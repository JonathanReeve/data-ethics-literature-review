{"offset": 0, "data": [{"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "0d2c546746a24ed1a3de02cb5a55680f356e2013", "externalIds": {"MAG": "3158352969", "DOI": "10.1177/14614448211011447"}, "url": "https://www.semanticscholar.org/paper/0d2c546746a24ed1a3de02cb5a55680f356e2013", "title": "Tactics of news literacy: How young people access, evaluate, and engage with news on social media", "abstract": "Young people\u2019s increasing dependence on social media for news demands increasing levels of news literacy, leading to a rise in media literacy programs that aim to support youth\u2019s abilities to criti...", "venue": "", "year": 2021, "referenceCount": 55, "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Sociology"], "authors": [{"authorId": "51032036", "name": "Jo\u00eblle Swart"}]}}, {"contexts": ["For example, it is estimated that 42% of the daily active users of Instagram have made at least one infuencerbased purchase in their past [6]; 23% of Facebook\u2019s daily users have already made purchases on the recommendation of bloggers or infuencers [5] and on Twitter, 29% of the platform\u2019s daily users have done so [5].", "This contributes to current discussions about nontransparent recommendation algorithms, such as algorithm-based timelines on Twitter [16] or the potential impacts on video recommendation on YouTube [2] and how to integrate those algorithms into design [40] ."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "1cef7226f9b5dc97c7d7f8488d9548b15d4f6ada", "externalIds": {"DBLP": "conf/chi/Weber0BG21", "DOI": "10.1145/3411764.3445607"}, "url": "https://www.semanticscholar.org/paper/1cef7226f9b5dc97c7d7f8488d9548b15d4f6ada", "title": "\u201cIt's a Kind of Art!\u201d: Understanding Food Influencers as Influential Content Creators", "abstract": "Although the number of influencers is increasing and being an influencer is one of the most frequently mentioned career aspirations of young people, we still know very little about influencers\u2019 motivations and actual practices from the HCI perspective. Driven by the emerging field of Human-Food Interaction and novel phenomena on social media such as Finstas, ASMR, Mukbang and live streaming, we would like to highlight the significance of food influencers as influential content creators and their social media practices. We have conducted a qualitative interview study and analyzed over 1,500 posts of food content creators on Instagram, focusing on practices of content creation, photography, staging, posting, and use of technology. Based on our findings, we have derived a process model that outlines the practices of this rather small, but influential user group. We contribute to the field of HCI by outlining the practices of food influencers as influential content creators within the social media sphere to open up design spaces for interaction researchers and practitioners.", "venue": "CHI", "year": 2021, "referenceCount": 72, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2052758083", "name": "Philip Weber"}, {"authorId": "144776974", "name": "Thomas Ludwig"}, {"authorId": "2089409869", "name": "Sabrina Brodesser"}, {"authorId": "2089409476", "name": "Laura Gr\u00f6newald"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "35ee53492c7f32dbb3b4ed7ba4d1395218b13ee9", "externalIds": {"ArXiv": "2105.02980", "DBLP": "journals/corr/abs-2105-02980", "DOI": "10.1145/3479577"}, "url": "https://www.semanticscholar.org/paper/35ee53492c7f32dbb3b4ed7ba4d1395218b13ee9", "title": "Everyday Algorithm Auditing: Understanding the Power of Everyday Users in Surfacing Harmful Algorithmic Behaviors", "abstract": "A growing body of literature has proposed formal approaches to audit algorithmic systems for biased and harmful behaviors. While formal auditing approaches have been greatly impactful, they often suffer major blindspots, with critical issues surfacing only in the context of everyday use once systems are deployed. Recent years have seen many cases in which everyday users of algorithmic systems detect and raise awareness about harmful behaviors that they encounter in the course of their everyday interactions with these systems. However, to date little academic attention has been granted to these bottom-up, user-driven auditing processes. In this paper, we propose and explore the concept of everyday algorithm auditing, a process in which users detect, understand, and interrogate problematic machine behaviors via their day-to-day interactions with algorithmic systems. We argue that everyday users are powerful in surfacing problematic machine behaviors that may elude detection via more centrally-organized forms of auditing, regardless of users' knowledge about the underlying algorithms. We analyze several real-world cases of everyday algorithm auditing, drawing lessons from these cases for the design of future platforms and tools that facilitate such auditing behaviors. Finally, we discuss work that lies ahead, toward bridging the gaps between formal auditing approaches and the organic auditing behaviors that emerge in everyday use of algorithmic systems.", "venue": "Proc. ACM Hum. Comput. Interact.", "year": 2021, "referenceCount": 228, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2110817340", "name": "Hong Shen"}, {"authorId": "2089778366", "name": "Alicia DeVos"}, {"authorId": "2419451", "name": "Motahhare Eslami"}, {"authorId": "2257481", "name": "Kenneth Holstein"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "36a4416f01465257f010078a84f28f4217727279", "externalIds": {"DOI": "10.1080/0144929x.2021.1987522"}, "url": "https://www.semanticscholar.org/paper/36a4416f01465257f010078a84f28f4217727279", "title": "Exploring folk theories of algorithmic news curation for explainable design", "abstract": null, "venue": "Behaviour & Information Technology", "year": 2021, "referenceCount": 32, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": null, "authors": [{"authorId": null, "name": "Thao Ngo"}, {"authorId": "116897043", "name": "Nicole Kr\u00e4mer"}]}}, {"contexts": ["Other works on resistance in HCI have associated it with complaint, for example when expectations around relied upon technologies are felt to be violated [24]."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "3835f0f3052349d99baadbe7f4c460927a27fb81", "externalIds": {"DBLP": "conf/chi/PenaCHV21", "DOI": "10.1145/3411764.3445128"}, "url": "https://www.semanticscholar.org/paper/3835f0f3052349d99baadbe7f4c460927a27fb81", "title": "Circumspect Users: Older Adults as Critical Adopters and Resistors of Technology", "abstract": "While HCI research has often addressed the needs of older adults, they are often framed as being sceptical of digital technologies. We argue that while many older adults are circumspect users of digital technology, they bring rich and critical perspectives on the role of technology in society that are grounded in lived experiences across their life courses. We report on 20 technology life story interviews conducted with retirees over the age of 60. Our analysis shows how experiences of technology across their life courses significantly undermined participants\u2019 sense of competency, independence, resilience, agency and control. Dissonances between what our participants valued and the perceived values of technology have led them to become critical adopters of technology, and resist its intrusion into certain aspects of their lives. We discuss how the critical perspectives of older adults and the value dissonances they experience are valuable for designing future digital technologies.", "venue": "CHI", "year": 2021, "referenceCount": 85, "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1825249661", "name": "Bel\u00e9n Barros Pena"}, {"authorId": "143949555", "name": "Rachel Clarke"}, {"authorId": "1696081", "name": "L. Holmquist"}, {"authorId": "145888680", "name": "J. Vines"}]}}, {"contexts": ["Through the idea of nestedness, it becomes clear that any form of change\u2014be it the \u201crupture\u201d of a new algorithm (DeVito et al., 2017; Petre et al., 2019) or a user movement that seems to reshuffle the industry ecology\u2014cannot be understood discretely; rather, precarity is located within wider\u2026", "Through the idea of nestedness, it becomes clear that any form of change\u2014be it the \u201crupture\u201d of a new algorithm (DeVito et al., 2017; Petre et al., 2019) or a user movement that seems to reshuffle the industry ecology\u2014cannot be understood discretely; rather, precarity is located within wider regimes of instability\u2014much like Russian Matryoshka dolls nested within one another.", "Thus, much like ordinary users who rely upon algorithmic imaginaries (Bucher, 2017) or \u201cfolk theories\u201d (Eslami et al., 2016; DeVito et al., 2017) to make sense of purportedly \u201cblack-boxed\u201d algorithmic systems, cultural producers developed and circulated platform-centric algorithmic theories in\u2026", "\u201d Thus, much like ordinary users who rely upon algorithmic imaginaries (Bucher, 2017) or \u201cfolk theories\u201d (Eslami et al., 2016; DeVito et al., 2017) to make sense of purportedly \u201cblack-boxed\u201d algorithmic systems, cultural producers developed and circulated platform-centric algorithmic theories in earnest."], "isInfluential": true, "intents": ["background"], "citingPaper": {"paperId": "4a8f77d9c94619213c7b0fd4e76aa732dbceb859", "externalIds": {"DOI": "10.1177/20563051211021368"}, "url": "https://www.semanticscholar.org/paper/4a8f77d9c94619213c7b0fd4e76aa732dbceb859", "title": "The Nested Precarities of Creative Labor on Social Media", "abstract": "While metrics have long played an important, albeit fraught, role in the media and cultural industries, quantified indices of online visibility\u2014likes, favorites, subscribers, and shares\u2014have been indelibly cast as routes to professional success and status in the digital creative economy. Against this backdrop, this study sought to examine how creative laborers\u2019 pursuit of social media visibility impacts their processes and products. Drawing upon in-depth interviews with 30 aspiring and professional content creators on a range of social media platforms\u2014Instagram, YouTube, TikTok, Pinterest, and Twitter\u2014we contend that their experiences are not only shaped by the promise of visibility, but also by its precarity. As such, we present a framework for assessing the volatile nature of visibility in platformized creative labor, which includes unpredictability across three levels: (1) markets, (2) industries, and (3) platform features and algorithms. After mapping out this ecological model of the nested precarities of visibility, we conclude by addressing both continuities with\u2014and departures from\u2014the earlier modes of instability that characterized cultural production, with a focus on the guiding logic of platform capitalism.", "venue": "Social Media + Society", "year": 2021, "referenceCount": 78, "citationCount": 2, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": null, "authors": [{"authorId": "20537832", "name": "B. Duffy"}, {"authorId": "2117560524", "name": "Annika Pinch"}, {"authorId": "10763415", "name": "Shruti Sannon"}, {"authorId": "2107498", "name": "M. Sawey"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "5b37d7c9f8a02de44ad130df558d34aa5795ff16", "externalIds": {"MAG": "3181857665", "DOI": "10.5167/UZH-203937"}, "url": "https://www.semanticscholar.org/paper/5b37d7c9f8a02de44ad130df558d34aa5795ff16", "title": "Making Sense of Metrics in the Music Industries", "abstract": "This article considers how media workers and organizations make use of the abundance of metrics available in the contemporary online environment. The expansion of audience measurement on digital music platforms, dashboard analytics, and third-party providers raises broad societal concerns about the quantification of culture; however, less attention has been paid to how professionals in the music industries approach, understand, and deploy these metrics in their work. Drawing on survey and interview data, we found that music workers do not take metrics on faith or reject them out of hand; rather, they make sense of them, deploy them strategically, and narrate their meanings to give themselves rationales to make investments and predictions and to persuade others to do so.", "venue": "", "year": 2021, "referenceCount": 65, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Sociology"], "authors": [{"authorId": "2556863", "name": "N. Baym"}, {"authorId": "2004573941", "name": "Rachel Bergmann"}, {"authorId": "94508149", "name": "R. Bhargava"}, {"authorId": "144085527", "name": "Fernando D. Diaz"}, {"authorId": "2650288", "name": "Tarleton Gillespie"}, {"authorId": "3972222", "name": "D. Hesmondhalgh"}, {"authorId": "114593226", "name": "Elena Maris"}, {"authorId": "116835987", "name": "Christopher J. Persaud"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "5f12e64c5686d2563044ac2dac583b3eb30b1b69", "externalIds": {"DOI": "10.1080/1369118x.2021.1989011"}, "url": "https://www.semanticscholar.org/paper/5f12e64c5686d2563044ac2dac583b3eb30b1b69", "title": "Making sense of algorithmic profiling: user perceptions on Facebook", "abstract": null, "venue": "Information, Communication & Society", "year": 2021, "referenceCount": 55, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": null, "authors": [{"authorId": "8052052", "name": "Moritz B\u00fcchi"}, {"authorId": "1434801262", "name": "E. Fosch-Villaronga"}, {"authorId": "6889723", "name": "C. Lutz"}, {"authorId": "1410283336", "name": "A. Tam\u00f3-Larrieux"}, {"authorId": "1417840064", "name": "Shruthi Velidi"}]}}, {"contexts": ["Recent studies have examined folk theories that people give for how they think an algorithm works (DeVito et al., 2017; Eslami et al., 2016; French & Hancock, 2017; Siles et al., 2020; Toff & Nielsen, 2018).", "Finally, because Crystal was an unknown algorithm that people were confronted with, this study builds on our understanding of \u201csnap\u201d folk theories, which are distinct from familiar theories built over time (DeVito et al., 2017; Eslami et al., 2016).", "While algorithmic folk theory research is a growing area, much of the existing work has focused on social media feeds (DeVito et al., 2017; Eslami et al., 2016; Rader & Gray, 2015), video and streaming sites (Siles et al., 2019), search engines (Toff & Nielsen, 2018), and music recommendation\u2026", "They are simultaneously an object of study, an implicit collection of beliefs about the system, and an analytical frame to understand and rationalize people\u2019s behaviors surrounding algorithms (DeVito et al., 2017; Rader & Gray, 2015).", "Much of the existing literature on folk theories have been focused on one dimension (e.g., algorithmic process) and how people believe a\nparticular feed functions (DeVito et al., 2017; Rader & Gray, 2015; Skrubbeltrang et al., 2017).", "Some folk theories have also surfaced when certain companies made changes to their algorithms, such as moving from a time-based to a curated feed (DeVito et al., 2017; Rader & Gray, 2015; Skrubbeltrang et al., 2017)."], "isInfluential": true, "intents": ["background"], "citingPaper": {"paperId": "6789db9daf133556313d686ff91d2c9fc5a508c9", "externalIds": {"MAG": "3154112498", "DOI": "10.1177/20563051211010170"}, "url": "https://www.semanticscholar.org/paper/6789db9daf133556313d686ff91d2c9fc5a508c9", "title": "\u201cCrystal Is Creepy, but Cool\u201d: Mapping Folk Theories and Responses to Automated Personality Recognition Algorithms", "abstract": "This article examines Crystal Knows, a company that generates automated personality profiles through an algorithm and sells access to their database. These algorithms are the result of a long line of research into computational and predictive algorithms that track social media practices and uses them to infer individual characteristics and make psychometric assessments. Although it is now computationally possible, these algorithms are not widely known or understood by the general public. Little is known about how people would respond to them, particularly when they do not even know their online activities are being assessed by the algorithm. This study examines how people construct \u201csnap\u201d folk theories about the ways personality algorithms operate as well as how they react when shown their outputs. Through qualitative interviews (n\u2009=\u200937) with people after being presented with their own profile, this study identifies a series of folk theories that people came up with to explain the personality algorithm across four dimensions (data source, scope, collection process, and outputs). In addition, this study examined how those folk theories contributed to certain reactions, fears, and justifications people had about the algorithm. This study builds on our theoretical understanding of folk theory literature as well as certain limitations of algorithmic transparency/sovereignty when these types of inferential and predictive algorithms get coupled with people\u2019s hopes and fears about employment, hiring, and promotion.", "venue": "Social Media + Society", "year": 2021, "referenceCount": 64, "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "39795271", "name": "T. Liao"}, {"authorId": "147758258", "name": "Olivia Tyson"}]}}, {"contexts": ["The development of algorithmic folk theories, unofficial theories a user holds to explain how a technological system operates and generates various outputs [27], is a powerful way for users of online platforms to make sense of what they see and experience on these platforms [26, 30, 32].", "For example, algorithmic folk theories can influence users\u2019 actions through online hashtag campaigns to expose and resist possible platform changes [27]."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "6f00a94d07ad0b790df6d9d9f061efcfbf4c45da", "externalIds": {"DBLP": "journals/pacmhci/KarizatDEA21", "DOI": "10.1145/3476046"}, "url": "https://www.semanticscholar.org/paper/6f00a94d07ad0b790df6d9d9f061efcfbf4c45da", "title": "Algorithmic Folk Theories and Identity: How TikTok Users Co-Produce Knowledge of Identity and Engage in Algorithmic Resistance", "abstract": "Algorithms in online platforms interact with users' identities in different ways. However, little is known about how users understand the interplay between identity and algorithmic processes on these platforms, and if and how such understandings shape their behavior on these platforms in return. Through semi-structured interviews with 15 US-based TikTok users, we detail users' algorithmic folk theories of the For You Page algorithm in relation to two inter-connected identity types: person and social identity. Participants identified potential harms that can accompany algorithms' tailoring content to their person identities. Further, they believed the algorithm actively suppresses content related to marginalized social identities based on race and ethnicity, body size and physical appearance, ability status, class status, LGBTQ identity, and political and social justice group affiliation. We propose a new algorithmic folk theory of social feeds-The Identity Strainer Theory-to describe when users believe an algorithm filters out and suppresses certain social identities. In developing this theory, we introduce the concept of algorithmic privilege as held by users positioned to benefit from algorithms on the basis of their identities. We further propose the concept of algorithmic representational harm to refer to the harm users experience when they lack algorithmic privilege and are subjected to algorithmic symbolic annihilation. Additionally, we describe how participants changed their behaviors to shape their algorithmic identities to align with how they understood themselves, as well as to resist the suppression of marginalized social identities and lack of algorithmic privilege via individual actions, collective actions, and altering their performances. We theorize our findings to detail the ways the platform's algorithm and its users co-produce knowledge of identity on the platform. We argue the relationship between users' algorithmic folk theories and identity are consequential for social media platforms, as it impacts users' experiences, behaviors, sense of belonging, and perceived ability to be seen, heard, and feel valued by others as mediated through algorithmic systems.", "venue": "Proc. ACM Hum. Comput. Interact.", "year": 2021, "referenceCount": 145, "citationCount": 2, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2119340514", "name": "Nadia Karizat"}, {"authorId": "120982620", "name": "Dan Delmonaco"}, {"authorId": "2419451", "name": "Motahhare Eslami"}, {"authorId": "2471896", "name": "Nazanin Andalibi"}]}}, {"contexts": ["And as has been shown in prior work [25], participants have strong opinions about how the news feed curation operates: \u201cI think the algorithm accuracy is pretty bad also."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "7a0aae2c0014413809e2b8e1c638c755445543c8", "externalIds": {"DBLP": "journals/pacmhci/VaccaroXHK21", "DOI": "10.1145/3476059"}, "url": "https://www.semanticscholar.org/paper/7a0aae2c0014413809e2b8e1c638c755445543c8", "title": "Contestability For Content Moderation", "abstract": "Content moderation systems for social media have had numerous issues of bias, in terms of race, gender, and ability among many others. One proposal for addressing such issues in automated decision making is by designing for contestability, whereby users can shape and influence how decisions are made. In this study, we conduct a series of participatory design workshops with participants from communities that have experienced problems with social media content moderation in the past. Together with participants, we explore the idea of designing for contestability in content moderation and find that users' designs suggest three fruitful, practical avenues: adding representation, improving communication, and designing with compassion. We conclude with design recommendations drawn from participants' proposals, and reflect on the challenges that remain.", "venue": "Proc. ACM Hum. Comput. Interact.", "year": 2021, "referenceCount": 235, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2862178", "name": "Kristen Vaccaro"}, {"authorId": null, "name": "Ziang Xiao"}, {"authorId": "2072368141", "name": "Kevin Hamilton"}, {"authorId": "1680270", "name": "K. Karahalios"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "7c0d18733f6b23026a2ebea12924ded2588eb20d", "externalIds": {"DBLP": "journals/corr/abs-2103-08786", "ArXiv": "2103.08786", "DOI": "10.1145/3450613.3456835"}, "url": "https://www.semanticscholar.org/paper/7c0d18733f6b23026a2ebea12924ded2588eb20d", "title": "Fairness and Transparency in Recommendation: The Users\u2019 Perspective", "abstract": "Though recommender systems are defined by personalization, recent work has shown the importance of additional, beyond-accuracy objectives, such as fairness. Because users often expect their recommendations to be purely personalized, these new algorithmic objectives must be communicated transparently in a fairness-aware recommender system. While explanation has a long history in recommender systems research, there has been little work that attempts to explain systems that use a fairness objective. Even though the previous work in other branches of AI has explored the use of explanations as a tool to increase fairness, this work has not been focused on recommendation. Here, we consider user perspectives of fairness-aware recommender systems and techniques for enhancing their transparency. We describe the results of an exploratory interview study that investigates user perceptions of fairness, recommender systems, and fairness-aware objectives. We propose three features \u2013 informed by the needs of our participants \u2013 that could improve user understanding of and trust in fairness-aware recommender systems.", "venue": "UMAP", "year": 2021, "referenceCount": 77, "citationCount": 4, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "14472354", "name": "Nasim Sonboli"}, {"authorId": "2109847276", "name": "Jessie Smith"}, {"authorId": "2054106340", "name": "Florencia Cabral Berenfus"}, {"authorId": "1747150", "name": "R. Burke"}, {"authorId": "1844816", "name": "Casey Fiesler"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "7cc3414b8c0791f1d5e8f82ee65cb99a7a876774", "externalIds": {"DBLP": "journals/pacmhci/ScheuermanHD21", "ArXiv": "2108.04308", "DOI": "10.1145/3476058"}, "url": "https://www.semanticscholar.org/paper/7cc3414b8c0791f1d5e8f82ee65cb99a7a876774", "title": "Do Datasets Have Politics? Disciplinary Values in Computer Vision Dataset Development", "abstract": "Data is a crucial component of machine learning. The field is reliant on data to train, validate, and test models. With increased technical capabilities, machine learning research has boomed in both academic and industry settings, and one major focus has been on computer vision. Computer vision is a popular domain of machine learning increasingly pertinent to real-world applications, from facial recognition in policing to object detection for autonomous vehicles. Given computer vision's propensity to shape machine learning research and impact human life, we seek to understand disciplinary practices around dataset documentation - how data is collected, curated, annotated, and packaged into datasets for computer vision researchers and practitioners to use for model tuning and development. Specifically, we examine what dataset documentation communicates about the underlying values of vision data and the larger practices and goals of computer vision as a field. To conduct this study, we collected a corpus of about 500 computer vision datasets, from which we sampled 114 dataset publications across different vision tasks. Through both a structured and thematic content analysis, we document a number of values around accepted data practices, what makes desirable data, and the treatment of humans in the dataset construction process. We discuss how computer vision datasets authors value efficiency at the expense of care; universality at the expense of contextuality; impartiality at the expense of positionality; and model work at the expense of data work. Many of the silenced values we identify sit in opposition with social computing practices. We conclude with suggestions on how to better incorporate silenced values into the dataset creation and curation process.", "venue": "Proc. ACM Hum. Comput. Interact.", "year": 2021, "referenceCount": 218, "citationCount": 2, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "10691918", "name": "M. Scheuerman"}, {"authorId": "40081727", "name": "Emily L. Denton"}, {"authorId": "40540250", "name": "A. Hanna"}]}}, {"contexts": ["The majority of these studies\nfocus on social media news feeds (Bucher, 2017; DeVito et al., 2018, 2017; Eslami et al., 2015; Rader et al., 2018; Rader & Gray, 2015)."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "827272325f931bb401a208829c57566a77fd2497", "externalIds": {"MAG": "3152454557", "DOI": "10.5167/UZH-204503"}, "url": "https://www.semanticscholar.org/paper/827272325f931bb401a208829c57566a77fd2497", "title": "Algorithm Awareness as an Important Internet Skill: The Case of Voice Assistants", "abstract": "Voice assistants have become increasingly popular as part of digital technologies that people use in their everyday lives. Research on Internet use has shown that people\u2019s online experiences are influenced by their level of know-how about the platforms they use. Extending the literature on Internet skills, this article focuses on people\u2019s algorithm skills in the domain of voice assistants. Are people aware of how algorithms influence what information they receive when using voice assistants? Drawing on 83 interviews conducted in 5 countries, we find that only a few participants explicitly mentioned the terms algorithms and artificial intelligence. Still, many seemed to be aware of the existence of automatic decision-making processes in voice assistants. This awareness was not necessarily based on their own experience with voice assistants, however. Rather, it was often a result of experiences with other digital devices and services such as Google Search, Facebook, Amazon, or smartphones, as well as information from social contacts and the media. We discuss the relevance of being aware of algorithms as one dimension of Internet skills.", "venue": "", "year": 2021, "referenceCount": 62, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2089062257", "name": "Jonathan Gruber"}, {"authorId": "1779187", "name": "E. Hargittai"}, {"authorId": "1902713764", "name": "G\u00f6k\u00e7e Karaoglu"}, {"authorId": "1659159371", "name": "Lisa Brombach"}]}}, {"contexts": ["found that folk theories about said algorithm framed users\u2019 tweets of dissatisfaction [16]."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "8b0605dc500f4dcc44c76edec7233912860b191c", "externalIds": {"DBLP": "conf/chi/HsuLZFZK21", "DOI": "10.1145/3411764.3445424"}, "url": "https://www.semanticscholar.org/paper/8b0605dc500f4dcc44c76edec7233912860b191c", "title": "Attitudes Surrounding an Imperfect AI Autograder", "abstract": "Deployment of AI assessment tools in education is widespread, but work on students\u2019 interactions and attitudes towards imperfect autograders is comparatively lacking. This paper presents students\u2019 perceptions surrounding a \u223c 90% accurate automated short-answer grader that determined homework and exam credit in a college-level computer science course. Using surveys and interviews, we investigated students\u2019 knowledge about the autograder and their attitudes. We observed that misalignment between folk theories about how the autograder worked and how it actually worked could lead to suboptimal answer construction strategies. Students overestimated the autograder\u2019s probability of marking correct answers as wrong, and estimates of this probability were associated with dissatisfaction and perceptions of unfairness. Many participants expressed a need for additional instruction on how to cater to the autograder. From these findings, we propose guidelines for incorporating imperfect short answer autograders into classroom in a manner that is considerate of students\u2019 needs.", "venue": "CHI", "year": 2021, "referenceCount": 76, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1666296676", "name": "Silas Hsu"}, {"authorId": "2109835731", "name": "T. Li"}, {"authorId": "2109379252", "name": "Zhilin Zhang"}, {"authorId": "70066419", "name": "Max Fowler"}, {"authorId": "3115032", "name": "C. Zilles"}, {"authorId": "1680270", "name": "K. Karahalios"}]}}, {"contexts": ["uring what is appropriate [15] because of the lack of explanation after content removal in online spaces [28]."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "9929d288926d73bb5855a576883e74f5a2f5a330", "externalIds": {"DBLP": "conf/tvx/CaiWA21", "DOI": "10.1145/3452918.3458796"}, "url": "https://www.semanticscholar.org/paper/9929d288926d73bb5855a576883e74f5a2f5a330", "title": "Moderation Visibility: Mapping the Strategies of Volunteer Moderators in Live Streaming Micro Communities", "abstract": "Volunteer moderators actively engage in online content management, such as removing toxic content and sanctioning anti-normative behaviors in user-governed communities. The synchronicity and ephemerality of live-streaming communities pose unique moderation challenges. Based on interviews with 21 volunteer moderators on Twitch, we mapped out 13 moderation strategies and presented them in relation to the bad act, enabling us to categorize from proactive and reactive perspectives and identify communicative and technical interventions. We found that the act of moderation involves highly visible and performative activities in the chat and invisible activities involving coordination and sanction. The juxtaposition of real-time individual decision-making with collaborative discussions and the dual nature of visible and invisible activities of moderators provide a unique lens into a role that relies heavily on both the social and technical. We also discuss how the affordances of live-streaming contribute to these unique activities.", "venue": "IMX", "year": 2021, "referenceCount": 84, "citationCount": 5, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2109852673", "name": "J. Cai"}, {"authorId": "2379340", "name": "D. Y. Wohn"}, {"authorId": "138177979", "name": "M. Almoqbel"}]}}, {"contexts": ["CSCW and HCI researchers have focused on sociotechnical aspects of content moderation, such as sociotechnical mechanisms of moderation or social practices of moderators [47,48,95,96]."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "d11e090cc0a3b470780272e0929f2d897d4a70f2", "externalIds": {"DBLP": "journals/pacmhci/MaK21", "DOI": "10.1145/3479573"}, "url": "https://www.semanticscholar.org/paper/d11e090cc0a3b470780272e0929f2d897d4a70f2", "title": "\"How advertiser-friendly is my video?\": YouTuber's Socioeconomic Interactions with Algorithmic Content Moderation", "abstract": "To manage user-generated harmful video content, YouTube relies on AI algorithms (e.g., machine learning) in content moderation and follows a retributive justice logic to punish convicted YouTubers through demonetization, a penalty that limits or deprives them of advertisements (ads), reducing their future ad income. Moderation research is burgeoning in CSCW, but relatively little attention has been paid to the socioeconomic implications of YouTube's algorithmic moderation. Drawing from the lens of algorithmic labor, we describe how algorithmic moderation shapes YouTubers' labor conditions through algorithmic opacity and precarity. YouTubers coped with such challenges from algorithmic moderation by sharing and applying practical knowledge they learned about moderation algorithms. By analyzing video content creation as algorithmic labor, we unpack the socioeconomic implications of algorithmic moderation and point to necessary post-punishment support as a form of restorative justice. Lastly, we put forward design considerations for algorithmic moderation systems.", "venue": "Proc. ACM Hum. Comput. Interact.", "year": 2021, "referenceCount": 174, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": null, "name": "Renkai Ma"}, {"authorId": "145508813", "name": "Yubo Kou"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "db890e7196f28673e688ce5c0bf95392c963b72a", "externalIds": {"DBLP": "journals/tis/Dogruel21", "DOI": "10.1080/01972243.2021.1949768"}, "url": "https://www.semanticscholar.org/paper/db890e7196f28673e688ce5c0bf95392c963b72a", "title": "Folk theories of algorithmic operations during Internet use: A mixed methods study", "abstract": "Abstract We used the folk theory perspective to investigate Internet users\u2019 understanding of algorithms during their Internet use. Empirically, we conducted a mixed-method study. First, we carried out semi-structured in-person interviews with 30 German Internet users. Our analysis of these interviews enabled us to identity five folk theories \u2013 economic orientation theory, personal interaction theory, popularity theory, categorization theory, and algorithmic thinking theory. In a second step, we created a standardized survey questionnaire with 19 illustrative statements for these five folk theories, relying on participants\u2019 explanations in the interviews to develop statements that reflected lay users\u2019 ideas as much as possible. Participants (N\u2009=\u2009331) were recruited through a commercial online access panel using quota criteria for age, gender, and education level to have a sample representative of the German population. Our survey findings indicate the prevalence of such folk theories among a broader population of Internet users, except for the algorithmic thinking theory, which is likely due to it being based on inaccurate assumptions about algorithms\u2019 capabilities.", "venue": "Inf. Soc.", "year": 2021, "referenceCount": 82, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2420895", "name": "Leyla Dogruel"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "dddf8ba364c064e910b4a515d7516c48e657cf0f", "externalIds": {"DOI": "10.1111/jan.15000", "PubMed": "34346514"}, "url": "https://www.semanticscholar.org/paper/dddf8ba364c064e910b4a515d7516c48e657cf0f", "title": "Practical strategies for qualitative inquiry in a virtual world.", "abstract": "AIM\nThe aim of this article is to provide practical strategies for maintaining methodological rigour in executing a virtual qualitative study. Strategies are based on evidence from existing research about virtual qualitative methods and on the strategies used by the authors to convert a planned in-person qualitative, grounded theory study to an entirely virtual grounded theory study during the COVID-19 pandemic. The study began in-person in September 2019 and was converted to virtual in March 2020. Virtual data collection was completed in September 2020.\n\n\nDESIGN\nThis article provides a case exemplar of virtual adaptations made to a study underway when the pandemic rendered all in-person research impractical and potentially dangerous.\n\n\nDATA SOURCES\nThe strategies discussed are based on our own experiences and the supporting theoretical assumptions of qualitative research, specifically grounded theory methods.\n\n\nIMPLICATIONS FOR NURSING\nNursing scholars conducting qualitative inquiry may find these strategies helpful in continuing research activities during periods of limited access to the phenomena or persons of interest. Furthermore, these strategies allow nursing scholars to conduct rigorous, in-depth research without geographical limitations, providing greater possibilities for international collaborations and cross-institution research.\n\n\nCONCLUSION\nDespite novel challenges, methodological adaptations that are carefully planned and purposeful allow qualitative and non-qualitative scholars to continue research activities in a fully virtual manner.\n\n\nIMPACT\nThis case exemplar and discussion provide practical strategies for qualitative scholars to consider while planning new studies or converting an in-person study to a virtual one. Despite the in-person nature of in-depth qualitative inquiry, a historic pandemic and a changing research environment require qualitative researchers to adapt to virtual methods while still conducting high quality, methodologically rigorous research. Qualitative scholars can use the strategies presented here to continue rigorous qualitative inquiry despite limited access to phenomena or persons.", "venue": "Journal of advanced nursing", "year": 2021, "referenceCount": 25, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Medicine"], "authors": [{"authorId": "24531001", "name": "E. Schlegel"}, {"authorId": "3742506", "name": "J. Tate"}, {"authorId": "5296721", "name": "R. Pickler"}, {"authorId": null, "name": "Laureen H Smith"}]}}, {"contexts": ["Specific works have uncovered folk theories of Twitter [14], Facebook [18], and Spotify [51]."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "eefb19e5917e6c1aab3cf566c520c1e9f416bdd8", "externalIds": {"DBLP": "conf/tei/0001AGGV21", "DOI": "10.1145/3430524.3440631"}, "url": "https://www.semanticscholar.org/paper/eefb19e5917e6c1aab3cf566c520c1e9f416bdd8", "title": "Exploring Tangible Algorithmic Imaginaries in Movie Recommendations", "abstract": "Recommender algorithms play an active role in many everyday activities. However, personalized recommendations often produce negative experiences due to a lack of awareness, control, or transparency. Allowing users to materialize their algorithmic imaginaries exposes how they experience, perceive, and imagine recommender algorithms. Moreover, it can unearth novel and previously unattended design opportunities for tangible interactions with algorithms. Therefore, we explored how 15 users of a famous movie recommender system materialized tangible designs to reflect and discuss their algorithmic imaginaries during co-design workshops and interviews. Using thematic analysis, we identified two forms of algorithmic imaginaries that can inspire tangible interactions with recommender algorithms: metaphoric and datafied representations. Complementary themes exposed the influence of contextual factors and diverse negative attitudes towards personalized movie recommendations. Based on these findings, we suggest design opportunities and suggestions for improving the algorithmic experience of movie recommendations and similar systems through tangible user interfaces.", "venue": "TEI", "year": 2021, "referenceCount": 78, "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "98223541", "name": "Oscar Alvarado"}, {"authorId": "8474018", "name": "V. V. Abeele"}, {"authorId": "1802499", "name": "D. Geerts"}, {"authorId": "143831925", "name": "Francisco Guti\u00e9rrez"}, {"authorId": "2629441", "name": "K. Verbert"}]}}, {"contexts": [", number of likes) may lead freelancers to make inaccurate conclusions about the appeal of their work [24, 31, 42]."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "fcd21b34279d29a79f3e136b0a7266da3ecd1804", "externalIds": {"DBLP": "journals/pacmhci/FoongKDG21", "DOI": "10.1145/3449096"}, "url": "https://www.semanticscholar.org/paper/fcd21b34279d29a79f3e136b0a7266da3ecd1804", "title": "CrowdFolio: Understanding How Holistic and Decomposed Workflows Influence Feedback on Online Portfolios", "abstract": "Freelancers increasingly earn their livelihood through online marketplaces. To attract new clients, freelancers continuously curate their online portfolios to convey their unique skills and style. However, many lack access to rapid, regular, and inexpensive feedback needed to improve their portfolios. Existing crowd feedback systems, which collect feedback on individual creative projects (i.e., decomposed approach), could fill this need, but it is unclear how they might support feedback on multiple projects (i.e., holistic approach). In a between-subjects study with 30 freelancers, we compared decomposed and holistic feedback collection approaches using CrowdFolio, a crowd feedback system for portfolios. The holistic approach helped freelancers discover new ways to describe their work, while the decomposed approach provided detailed insight about the visual attractiveness of projects. This study contributes evidence that portfolio feedback systems, regardless of collection approach, can positively support professional development by impacting how freelancers portray themselves online and reflect on their identity.", "venue": "Proc. ACM Hum. Comput. Interact.", "year": 2021, "referenceCount": 70, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "10755211", "name": "Eureka Foong"}, {"authorId": "1667470535", "name": "Joy Kim"}, {"authorId": "2875493", "name": "Mira Dontcheva"}, {"authorId": "145003123", "name": "E. Gerber"}]}}, {"contexts": ["also examined folk theories of curation by platforms, but in the specific context of a large-scale negative reaction to platform change to diagnose the nature and causes of the backlash [26].", "[26], and encompass many of the folk theories found in prior work (e.", "As work on more general populations [25, 26, 31, 32, 88] focuses only on initial folk theory formation, we do not yet have a detailed understanding of the everyday process of repeated folk theorization and adaptation that casual,", "advanced the idea that we do not adequately examine low-level (or \u201cabstract\u201d) understandings of algorithms, and therefore underestimate awareness [26].", "These theories explain how users deal with the complexity of platforms of which they have no direct technical knowledge [26].", ", [26]), and work on user understanding more generally (e.", "referred to as \u201cabstract theories,\u201d [26] and the functional theorist\u2019s process reflects the", "mechanistic knowledge that academic studies have identified, have plenty of opinions about algorithmically-driven systems and the companies that control them [102], and often conflate algorithmic change with the actions of the platform company as a whole [26, 101].", "In the context of HCI, folk theories are lay, sociallyconstructed conceptions of how a platform works, which the theorizer then uses to guide their on-platform decision-making behavior [25, 26].", "As seen in past studies, the truth of what is happening has minimal relevance to the user; they form folk theories, adapt, and even start protests with the knowledge they perceive [25, 26]."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "fe66d5553a9d80937761ede432e08b300f358c8a", "externalIds": {"DBLP": "journals/pacmhci/DeVito21", "DOI": "10.1145/3476080"}, "url": "https://www.semanticscholar.org/paper/fe66d5553a9d80937761ede432e08b300f358c8a", "title": "Adaptive Folk Theorization as a Path to Algorithmic Literacy on Changing Platforms", "abstract": "The increased importance of opaque, algorithmically-driven social platforms (e.g., Facebook, YouTube) to everyday users as a medium for self-presentation effectively requires users to speculate on how platforms work in order to decide how to behave to achieve their self-presentation goals. This speculation takes the form of folk theorization. Because platforms constantly change, users must constantly re-evaluate their folk theories. Based on an Asynchronous Remote Community study of LGBTQ+ social platform users with heightened self-presentation concerns, I present an updated model of the folk theorization process to account for platform change. Moreover, I find that both the complexity of the user's folk theorization and their overall relationship with the platform impact this theorization process, and present new concepts for examining and classifying these elements: theorization complexity level and perceived platform spirit. I conclude by proposing a folk theorization-based path towards an extensible algorithmic literacy that would support users in ongoing theorization.", "venue": "Proc. ACM Hum. Comput. Interact.", "year": 2021, "referenceCount": 176, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "32861190", "name": "M. DeVito"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "0047179c44defdd733a16dc3cda6fde423c92474", "externalIds": {"MAG": "3094956525", "DBLP": "conf/nordichi/0001SGV20", "DOI": "10.1145/3419249.3421237"}, "url": "https://www.semanticscholar.org/paper/0047179c44defdd733a16dc3cda6fde423c92474", "title": "Foregrounding Algorithms: Preparing Users for Co-design with Sensitizing Activities", "abstract": "Algorithms are present in many of our everyday activities. However, there is generally low awareness of their presence among users, and there are various conceptualizations to define them. Additionally, algorithms are often both complex and opaque. These characteristics raise challenges when applying co-design activities to the interaction design of algorithms. We argue that researchers can overcome these challenges by developing sensitizing activities: activities that foreground the presence of algorithms, thus raising algorithmic awareness and a shared understanding, without influencing their initial experiences and expectations. We share how we applied sensitizing activities in two case studies: sensitizing interviews, and diary studies together with two-phase workshops. We share our experiences applying these techniques to overcome the challenges of low algorithmic awareness and multiple algorithmic understandings of participants. Finally, we offer recommendations for researchers and practitioners when applying sensitizing activities in this design context and invite further methodological discussion on this challenging topic.", "venue": "NordiCHI", "year": 2020, "referenceCount": 45, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "98223541", "name": "Oscar Alvarado"}, {"authorId": "112892174", "name": "Elias Storms"}, {"authorId": "1802499", "name": "D. Geerts"}, {"authorId": "2629441", "name": "K. Verbert"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "1e3146d8158df5e447e37df0c118dfa16e8f3d8c", "externalIds": {"MAG": "3048014265", "DOI": "10.1007/978-3-030-49079-9_4"}, "url": "https://www.semanticscholar.org/paper/1e3146d8158df5e447e37df0c118dfa16e8f3d8c", "title": "New Digital Inequalities. Algorithms Divide", "abstract": "This chapter focuses on the rise of new digital inequalities by looking at the costs and consequences of algorithmic decision-making on citizens\u2019 everyday lives and how they are affecting social inequalities. More specifically, the chapter looks at the inequalities in (a) knowledge (inequalities intended as the different levels of understanding of how algorithms influence everyday life and different skills and creative techniques to escape algorithms\u2019 \u201csuggestions\u201d); (b) creating dataset (how data on which algorithms and AI are based are biased); and (c) treatment (the unequal treatment that AI and algorithms reserve for different individuals based on their socio-economic and socio-demographic characteristics). These three levels of (new) digital inequalities are tied both with the main axes of social inequalities and with the rise of digital technologies, and affect, often silently, citizens\u2019 lives and social hierarchy.", "venue": "", "year": 2020, "referenceCount": 85, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Sociology"], "authors": [{"authorId": "2049825", "name": "Massimo Ragnedda"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "35510d7f5a136908a35bc50eac3e39a8f39e8ab3", "externalIds": {"MAG": "3093600053", "DOI": "10.1177/0170840620970728"}, "url": "https://www.semanticscholar.org/paper/35510d7f5a136908a35bc50eac3e39a8f39e8ab3", "title": "Behavioral Visibility: A new paradigm for organization studies in the age of digitization, digitalization, and datafication", "abstract": "The digitization, digitalization, and datafication of work and communication, coupled with social and technical infrastructures that enable connectivity, are making it increasingly easy for the behaviors of people, collectives, and technological devices to see and be seen. Such digital connectivity gives rise to the important phenomenon of behavioral visibility. We argue that studying the antecedents, processes, and consequences of behavioral visibility should be a central concern for scholars of organizing. We attempt to set the cornerstones for the study of behavioral visibility by considering the social and technological contexts that are enabling behavioral visibility, developing the concept of behavioral visibility by defining its various components, considering the conditions through which it is commonly produced, and outlining potential consequences of behavioral visibility in the form of three paradoxes. We conclude with some conjectures about the kinds of research questions, empirical foci, and methodological strategies that scholars will need to embrace in order to understand how behavioral visibility shapes and is shaped by the process of organizing as we catapult, swiftly, into an era where artificial intelligence, learning algorithms, and social tools are changing the way people work.", "venue": "", "year": 2020, "referenceCount": 127, "citationCount": 21, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "34602963", "name": "P. Leonardi"}, {"authorId": "2054189", "name": "J. Treem"}]}}, {"contexts": ["Members of Twitter, for instance, expressed public outrage when the platform abruptly moved to an algorithmically ordered timeline (DeVito et al., 2017)."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "3dea89f8953423e8175ac4c78fc4fbd96fc47876", "externalIds": {"MAG": "3090601633", "DOI": "10.1177/2057047320959855"}, "url": "https://www.semanticscholar.org/paper/3dea89f8953423e8175ac4c78fc4fbd96fc47876", "title": "Algorithmic precarity in cultural work", "abstract": "While work in the media and cultural industries has long been considered precarious, the processes and logics of platformization have injected new sources of instability into the creative labor economy. Among the sources of such insecurity are platforms\u2019 algorithms, which structure the production, circulation, and consumption of cultural content in capricious, enigmatic, even biased ways. Accordingly, cultural producers\u2019 conditions and experiences are increasingly wrought by their understandings\u2014and moreover their anticipation\u2014of platforms\u2019 ever-evolving algorithmic systems. Against this backdrop, I urge fellow researchers of digital culture and society to consider how this mode of \u201calgorithmic precarity\u201d exacerbates the instability of cultural work in the platform era. Considering the volatility of algorithms and the wider cross-platform ecology can help us to develop critical interventions into a creative economy marked by a profoundly uneven allocation of power between platforms and the laborers who populate\u2014and increasingly\u2014power them.", "venue": "", "year": 2020, "referenceCount": 45, "citationCount": 3, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Sociology"], "authors": [{"authorId": "20537832", "name": "B. Duffy"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "5936b8dcaa3f57c1202e2e75870d4eeb83eb2d21", "externalIds": {"DBLP": "journals/jcmc/Sundar20", "MAG": "2998829516", "DOI": "10.1093/jcmc/zmz026"}, "url": "https://www.semanticscholar.org/paper/5936b8dcaa3f57c1202e2e75870d4eeb83eb2d21", "title": "Rise of Machine Agency: A Framework for Studying the Psychology of Human-AI Interaction (HAII)", "abstract": "\n Advances in personalization algorithms and other applications of machine learning have vastly enhanced the ease and convenience of our media and communication experiences, but they have also raised significant concerns about privacy, transparency of technologies and human control over their operations. Going forth, reconciling such tensions between machine agency and human agency will be important in the era of artificial intelligence (AI), as machines get more agentic and media experiences become increasingly determined by algorithms. Theory and research should be geared toward a deeper understanding of the human experience of algorithms in general and the psychology of Human\u2013AI interaction (HAII) in particular. This article proposes some directions by applying the dual-process framework of the Theory of Interactive Media Effects (TIME) for studying the symbolic and enabling effects of the affordances of AI-driven media on user perceptions and experiences.", "venue": "J. Comput. Mediat. Commun.", "year": 2020, "referenceCount": 65, "citationCount": 43, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Psychology"], "authors": [{"authorId": "47493614", "name": "S. Sundar"}]}}, {"contexts": ["Following the distinction developed by DeVito et al. (2017), the first three theories are operational in describing workings of algorithms, while the latter two are less specific.", "DeVito et al. (2017) separate \u201coperational theories\u201d of algorithms, which describe certain aspects of what the algorithm does, from \u201cabstract theories\u201d which are more generally mourning what was lost in a change.", "Instead, they rely on a more general sense that an algorithm is something that will, in turn, cause something to happen\u201d (DeVito et al., 2017: np).", "\u2026was not to conduct a thematic categorization of all subcategories in the material,3 but to group replies alluding to similar operational theories (DeVito et al., 2017) of what people believe algorithms do to media experiences, with search for more abstract theories of what algorithms are or mean\u2026"], "isInfluential": true, "intents": ["background", "methodology"], "citingPaper": {"paperId": "59906ad7db6836507f8b11dd4d43cc1c1c0524bb", "externalIds": {"MAG": "3113375623", "DOI": "10.1177/0163443720972314"}, "url": "https://www.semanticscholar.org/paper/59906ad7db6836507f8b11dd4d43cc1c1c0524bb", "title": "Folk theories of algorithms: Understanding digital irritation", "abstract": "This article draws on the framework of \u201cfolk theories\u201d to analyze how people perceive algorithms in the media. Taking algorithms as a prime case to investigate how people respond to datafication in everyday media use, we ask how people perceive positive and negative consequences of algorithms. To answer our question, we conduct qualitative thematic analysis of open-ended answers from a 2019 representative survey among Norwegians, identifying five folk theories: algorithms are confining, practical, reductive, intangible, and exploitative. We situate our analysis in relation to different application of folk theory approaches, and discuss our findings in light of emerging work on perceptions of algorithms and critiques of datafication, including the concept digital resignation. We conclude that rather than resignation, digital irritation emerges as a central emotional response, with a small but significant potential to inspire future political action against datafication.", "venue": "Media, Culture & Society", "year": 2020, "referenceCount": 56, "citationCount": 4, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1422431327", "name": "Brita Ytre-Arne"}, {"authorId": "38335278", "name": "Hallvard Moe"}]}}, {"contexts": ["Similarly, noticing inconsistent or unexpected content also corresponds to greater awareness of\nalgorithmic processes (DeVito et al., 2017; Rader & Gray, 2015)."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "5accdc1a0d62a4612659f3815fe038054ff98d56", "externalIds": {}, "url": "https://www.semanticscholar.org/paper/5accdc1a0d62a4612659f3815fe038054ff98d56", "title": "Algorithmic Knowledge Gaps: A New Dimension of (Digital) Inequality", "abstract": "Algorithms serve as gatekeepers and arbiters of truth online. Understanding how algorithms influence which information individuals encounter better enables them to properly calibrate their reception of the information. Yet, knowledge of platform algorithms appears to be limited and not universally distributed. In line with the long history of knowledge inequities, we suggest that algorithmic knowledge varies according to socioeconomic advantage. We further argue that algorithms are experience technologies in that they are more easily understood through use. Nevertheless, socioeconomic background continues to shape information and communication technology use, thereby further influencing disparities in algorithmic knowledge. Using data from a survey of a random sample of Internet users in the United States, we found support for the relationship between algorithmic knowledge and socioeconomic background in the context of online search. The findings provide preliminary evidence that extant structural inequalities underlie algorithmic knowledge gaps in this domain.", "venue": "", "year": 2020, "referenceCount": 65, "citationCount": 7, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": null, "authors": [{"authorId": "36606130", "name": "Kelley Cotter"}, {"authorId": "2871500", "name": "Bianca C. Reisdorf"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "5eb8348245fe8b4cdf9ef5df492cff1ce2bf6438", "externalIds": {"MAG": "3040936349", "DOI": "10.17645/mac.v8i3.3001"}, "url": "https://www.semanticscholar.org/paper/5eb8348245fe8b4cdf9ef5df492cff1ce2bf6438", "title": "Negotiated Autonomy: The Role of Social Media Algorithms in Editorial Decision Making", "abstract": "Social media platforms have increasingly become an important way for news organizations to distribute content to their audiences. As news organizations relinquish control over distribution, they may feel the need to optimize their content to align with platform logics to ensure economic sustainability. However, the opaque and often proprietary nature of platform algorithms makes it hard for news organizations to truly know what kinds of content are preferred and will perform well. Invoking the concept of algorithmic \u2018folk theories,\u2019 this article presents a study of in-depth, semi-structured interviews with 18 U.S.-based news journalists and editors to understand how they make sense of social media algorithms, and to what extent this influences editorial decision making. Our findings suggest that while journalists\u2019 understandings of platform algorithms create new considerations for gatekeeping practices, the extent to which it influences those practices is often negotiated against traditional journalistic conceptions of newsworthiness and journalistic autonomy.", "venue": "", "year": 2020, "referenceCount": 56, "citationCount": 10, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Sociology"], "authors": [{"authorId": "1485041488", "name": "Chelsea Peterson-Salahuddin"}, {"authorId": "2943892", "name": "N. Diakopoulos"}]}}, {"contexts": ["Algorithmic filtering (AF) [16, 28] has the potential to greatly improve the user experience.", "There are three parts to the definition of algorithmic filtering (AF) [16, 28]."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "69261de62c80769e1123b64d7814ffeb49e5d089", "externalIds": {"ArXiv": "2006.09647", "DBLP": "journals/corr/abs-2006-09647", "MAG": "3036405624"}, "url": "https://www.semanticscholar.org/paper/69261de62c80769e1123b64d7814ffeb49e5d089", "title": "Regulating algorithmic filtering on social media", "abstract": "Through the algorithmic filtering (AF) of content, social media platforms (SMPs) have the ability to influence users' perceptions and behaviors. Attempts to regulate externalities of AF are often difficult to pass or enforce due to critical social, legal, financial, and user related considerations. In this work, we explore this multifaceted problem by proposing a unifying framework that considers the key stakeholders of AF regulation (or self-regulation). We mathematically formalize this framework, using it to construct a data-driven, statistically sound regulatory procedure that satisfies several important criteria. First, by design, it moderates the effect of AF on user learning and decision-making. Second, it has desirable properties of online governance, including being normative and user-driven. Third, by illustrating the regulatory procedure in linear dynamical systems, we prove that it can align social and financial interests. Specifically, we identify conditions under which the regulation imposes a low cost on the SMP's reward (e.g., profits) and incentivizes the SMP to increase content diversity.", "venue": "ArXiv", "year": 2020, "referenceCount": 131, "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "51288622", "name": "Sarah H. Cen"}, {"authorId": "145081804", "name": "D. Shah"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "6d847d92ed6efbcd322549f732c014e9bfb1c45d", "externalIds": {"ArXiv": "2001.09604", "MAG": "3000966858", "DBLP": "journals/corr/abs-2001-09604", "DOI": "10.1145/3313831.3376813"}, "url": "https://www.semanticscholar.org/paper/6d847d92ed6efbcd322549f732c014e9bfb1c45d", "title": "Factors Influencing Perceived Fairness in Algorithmic Decision-Making: Algorithm Outcomes, Development Procedures, and Individual Differences", "abstract": "Algorithmic decision-making systems are increasingly used throughout the public and private sectors to make important decisions or assist humans in making these decisions with real social consequences. While there has been substantial research in recent years to build fair decision-making algorithms, there has been less research seeking to understand the factors that affect people's perceptions of fairness in these systems, which we argue is also important for their broader acceptance. In this research, we conduct an online experiment to better understand perceptions of fairness, focusing on three sets of factors: algorithm outcomes, algorithm development and deployment procedures, and individual differences. We find that people rate the algorithm as more fair when the algorithm predicts in their favor, even surpassing the negative effects of describing algorithms that are very biased against particular demographic groups. We find that this effect is moderated by several variables, including participants' education level, gender, and several aspects of the development procedure. Our findings suggest that systems that evaluate algorithmic fairness through users' feedback must consider the possibility of \"outcome favorability\" bias.", "venue": "CHI", "year": 2020, "referenceCount": 129, "citationCount": 35, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Psychology", "Computer Science"], "authors": [{"authorId": "2108694939", "name": "Ruotong Wang"}, {"authorId": "145192090", "name": "F. M. Harper"}, {"authorId": "1742431", "name": "Haiyi Zhu"}]}}, {"contexts": ["ed us to further contextualize the results, by allowing participants to agree or disagree with the suggestions provided by the interviewers, an aspect that is usually not measured in previous studies [14, 16, 43]. Moreover, the third phase allowed participants to express other beliefs that they could have forgotten during the second phase. 3.3 Analysis The interviews were analyzed using thematic analysis, a \u201c", "n be related to the \u201cWhen do I watch\u201d, \u201c\u2018Where do I watch\u201d and the \u201cPsychological Experts\u201d influences [16]. All of these influences are also similar to the operational theories found by DeVito et al. [14]. Influence factors such as \u201cMy Watch History\u201d, \u201cMy Search History\u201d, \u201cMy Comments\u201d, \u201cOthers\u2019 Comments\u201d, \u201cMy User Subscriptions\u201d, \u201cMy Likes &amp; Dislikes\u201d, and \u201cOthers\u2019 Likes &amp; Dislikes\u201d, are spec"], "isInfluential": true, "intents": ["background"], "citingPaper": {"paperId": "7e6cd4ff24b4db872cb4bf163d136ae5fefcc23c", "externalIds": {"MAG": "3103404493", "DBLP": "journals/pacmhci/AlvaradoHABV20", "ArXiv": "2008.03202", "DOI": "10.1145/3415192"}, "url": "https://www.semanticscholar.org/paper/7e6cd4ff24b4db872cb4bf163d136ae5fefcc23c", "title": "Middle-Aged Video Consumers' Beliefs About Algorithmic Recommendations on YouTube", "abstract": "User beliefs about algorithmic systems are constantly co-produced through user interaction and the complex socio-technical systems that generate recommendations. Identifying these beliefs is crucial because they influence how users interact with recommendation algorithms. With no prior work on user beliefs of algorithmic video recommendations, practitioners lack relevant knowledge to improve the user experience of such systems. To address this problem, we conducted semi-structured interviews with middle-aged YouTube video consumers to analyze their user beliefs about the video recommendation system. Our analysis revealed different factors that users believe influence their recommendations. Based on these factors, we identified four groups of user beliefs: Previous Actions, Social Media, Recommender System, and Company Policy. Additionally, we propose a framework to distinguish the four main actors that users believe influence their video recommendations: the current user, other users, the algorithm, and the organization. This framework provides a new lens to explore design suggestions based on the agency of these four actors. It also exposes a novel aspect previously unexplored: the effect of corporate decisions on the interaction with algorithmic recommendations. While we found that users are aware of the existence of the recommendation system on YouTube, we show that their understanding of this system is limited.", "venue": "Proc. ACM Hum. Comput. Interact.", "year": 2020, "referenceCount": 77, "citationCount": 5, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "98223541", "name": "Oscar Alvarado"}, {"authorId": "34698604", "name": "Hendrik Heuer"}, {"authorId": "8474018", "name": "V. V. Abeele"}, {"authorId": "3251859", "name": "A. Breiter"}, {"authorId": "2629441", "name": "K. Verbert"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "8adea7ae0f5d0d1759804e17091785d3abf9e7e8", "externalIds": {"MAG": "3014032479", "DOI": "10.1080/1369118X.2020.1713846"}, "url": "https://www.semanticscholar.org/paper/8adea7ae0f5d0d1759804e17091785d3abf9e7e8", "title": "Black box measures? How to study people\u2019s algorithm skills", "abstract": "ABSTRACT Considerable scholarship has established that algorithms are an increasingly important part of what information people encounter in everyday life. Much less work has focused on studying users\u2019 experiences with, understandings of, and attitudes about how algorithms may influence what they see and do. The dearth of research on this topic globally with diverse populations may be in part due to the difficulty of studying a subject about which there is no known ground truth given that details about algorithms are proprietary and rarely made public. This paper explicitly takes on the methodological challenges of studying people\u2019s algorithm skills to shed light on the special considerations required when studying a topic about which even the researchers possess limited know-how. The paper advocates for more such scholarship to accompany existing system-level analyses of algorithms\u2019 social implications and offers a blueprint for how to do so.", "venue": "", "year": 2020, "referenceCount": 53, "citationCount": 12, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Sociology"], "authors": [{"authorId": "1779187", "name": "E. Hargittai"}, {"authorId": "2089062257", "name": "Jonathan Gruber"}, {"authorId": "1420424297", "name": "Teodora Djukaric"}, {"authorId": "1418836134", "name": "Jaelle Fuchs"}, {"authorId": "1659159371", "name": "Lisa Brombach"}]}}, {"contexts": ["Several scholars have focused on the development of evolving and malleable folk theories around algorithmic systems in order to: better understand their outcomes and effects, such as how they guide an individual\u2019s behavior and self-presentation practices [35, 36]; to account for news information discovery [130]; and to understand the way affordances can manipulate Facebook\u2019s News Feed [46].", "We can find algorithms embedded in the digital infrastructures we encounter and use in our daily lives ranging from traditional news media [55] and search engines [11, 18, 99], to social media platforms [36]."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "b149e36bd051ca3952e501f9e0fc5161c825592e", "externalIds": {"DBLP": "journals/pacmhci/SimpsonS20", "DOI": "10.1145/3432951"}, "url": "https://www.semanticscholar.org/paper/b149e36bd051ca3952e501f9e0fc5161c825592e", "title": "For You, or For\"You\"?", "abstract": "Online communities provide spaces for people who are vulnerable and underserved to seek support and build community, such as LGBTQ+ people. Today, some online community spaces are mediated by algorithms. Scholarship has found that algorithms have become deeply embedded in the systems that mediate our routine engagements with the world. Yet, little is known about how these systems impact those who are most vulnerable in society. In this paper, we focus on people's everyday experiences with one algorithmic system, the short video sharing application TikTok. TikTok recently received press that it was suppressing and oppressing the identities of its growing LGBTQ+ user population through algorithmic and human moderation of LGBTQ+ creators and content related to LGBTQ+ identity. Through an interview study with 16 LGBTQ+ TikTok users, we explore people's everyday engagements and encounters with the platform. We find that TikTok's For You Page algorithm constructs contradictory identity spaces that at once support LGBTQ+ identity work and reaffirm LGBTQ+ identity, while also transgressing and violating the identities of individual users. We also find that people are developing self-organized practices in response to these transgressions and violations. We discuss the implications of algorithmic systems on people's identity work, and introduce the concept of algorithmic exclusion, and explore how people are building resilience following moments of algorithmic exclusion.", "venue": "Proc. ACM Hum. Comput. Interact.", "year": 2021, "referenceCount": 196, "citationCount": 2, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "33343119", "name": "Ellen Simpson"}, {"authorId": "3356301", "name": "Bryan C. Semaan"}]}}, {"contexts": ["Folk theories are \u201cintuitive, informal theories that individuals develop to explain the outcomes, effects, or consequences of technological systems, which guide reactions to and behavior towards said systems\u201d (DeVito et al., 2017: 3165)."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "b2617fdbadd44167790b2f92384c86d598d2f613", "externalIds": {"MAG": "3023481589", "DOI": "10.1177/2053951720923377"}, "url": "https://www.semanticscholar.org/paper/b2617fdbadd44167790b2f92384c86d598d2f613", "title": "Folk theories of algorithmic recommendations on Spotify: Enacting data assemblages in the global South", "abstract": "This paper examines folk theories of algorithmic recommendations on Spotify in order to make visible the cultural specificities of data assemblages in the global South. The study was conducted in Costa Rica and draws on triangulated data from 30 interviews, 4 focus groups with 22 users, and the study of \u201crich pictures\u201d made by individuals to graphically represent their understanding of algorithmic recommendations. We found two main folk theories: one that personifies Spotify (and conceives of it as a social being that provides recommendations thanks to surveillance) and another one that envisions it as a system full of resources (and a computational machine that offers an individualized musical experience through the appropriate kind of \u201ctraining\u201d). Whereas the first theory emphasizes local conceptions of social relations to make sense of algorithms, the second one stresses the role of algorithms in providing a global experience of music and technology. We analyze why people espouse either one of these theories (or both) and how these theories provide users with resources to enact different modalities of power and resistance in relation to recommendation algorithms. We argue that folk theories thus offer a productive way to broaden understanding of what agency means in relation to algorithms.", "venue": "", "year": 2020, "referenceCount": 69, "citationCount": 20, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Geography"], "authors": [{"authorId": "2299692", "name": "I. Siles"}, {"authorId": "1404580668", "name": "Andr\u00e9s Segura-Castillo"}, {"authorId": "153784473", "name": "R. Sol\u00eds"}, {"authorId": "47351101", "name": "M\u00f3nica Sancho"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "ccb9be43a91c0de0224009d2f1d624357a2a7cfe", "externalIds": {"MAG": "3094926932", "DOI": "10.1080/21670811.2020.1837639"}, "url": "https://www.semanticscholar.org/paper/ccb9be43a91c0de0224009d2f1d624357a2a7cfe", "title": "Taming the News Feed on Facebook: Understanding Consumptive News Feed Curation through a Social Cognitive Perspective", "abstract": "Abstract As algorithms are increasingly integrated into news selection and consumption processes, it is crucial to understand how news users respond to them. Drawing upon social cognitive theory, this study examined the underlying mechanisms of consumptive news feed curation, a type of news consumption behaviour through which news users could determine what shows up in their news feeds. Findings based on a national survey data in the United States showed that the proportion of Facebook users who practiced consumptive news feed curation remained low and the extent of such practices varied according to their socioeconomic and political backgrounds. The study further tested a moderated mediation model and found that Facebook use contributed to consumptive news feed curation through perceived knowledge, depending on levels of perceived user controllability. Theoretical and practical implications are discussed.", "venue": "", "year": 2020, "referenceCount": 57, "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Psychology"], "authors": [{"authorId": "3153416", "name": "Shuning Lu"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "1777c78fedc9d7b0432e12cb5a1aa6f5b53cf7c7", "externalIds": {"DBLP": "conf/chi/DeVito19", "MAG": "2942667983", "DOI": "10.1145/3290607.3299082"}, "url": "https://www.semanticscholar.org/paper/1777c78fedc9d7b0432e12cb5a1aa6f5b53cf7c7", "title": "User Adaptation to Constant Change in Algorithmically-Driven Social Platforms", "abstract": "Social platforms present a challenge for self-presentation and identity management by obscuring audiences behind algorithmic mechanisms. Users are increasingly aware of this and actively adapting through folk theorization, but we do not know how users are coping with the constant change endemic to these platforms, or how we can assist users in this coping process. My dissertation will examine how users perceive and adapt to the constantly-changing platform space using self-presentation and audience management as an illustrative case.", "venue": "CHI Extended Abstracts", "year": 2019, "referenceCount": 19, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "32861190", "name": "M. DeVito"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "1e8e2a2baca26b80b5bb8d46a257d99a432e7c34", "externalIds": {"MAG": "2942465698", "DBLP": "conf/chi/JakeschFMHN19", "DOI": "10.1145/3290605.3300469"}, "url": "https://www.semanticscholar.org/paper/1e8e2a2baca26b80b5bb8d46a257d99a432e7c34", "title": "AI-Mediated Communication: How the Perception that Profile Text was Written by AI Affects Trustworthiness", "abstract": "We are entering an era of AI-Mediated Communication (AI-MC) where interpersonal communication is not only mediated by technology, but is optimized, augmented, or generated by artificial intelligence. Our study takes a first look at the potential impact of AI-MC on online self-presentation. In three experiments we test whether people find Airbnb hosts less trustworthy if they believe their profiles have been written by AI. We observe a new phenomenon that we term the Replicant Effect: Only when participants thought they saw a mixed set of AI- and human-written profiles, they mistrusted hosts whose profiles were labeled as or suspected to be written by AI. Our findings have implications for the design of systems that involve AI technologies in online self-presentation and chart a direction for future work that may upend or augment key aspects of Computer-Mediated Communication theory.", "venue": "CHI", "year": 2019, "referenceCount": 91, "citationCount": 30, "influentialCitationCount": 7, "isOpenAccess": false, "fieldsOfStudy": ["Psychology", "Computer Science"], "authors": [{"authorId": "113179096", "name": "Maurice Jakesch"}, {"authorId": "143667081", "name": "Megan French"}, {"authorId": "2115573531", "name": "Xiao Ma"}, {"authorId": "1697703", "name": "J. Hancock"}, {"authorId": "1687465", "name": "M. Naaman"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "2623a1013a7c9cbce39961d69e7eee83bdbfc0c5", "externalIds": {"MAG": "2950999633", "DBLP": "conf/ACMdis/Maudet19", "DOI": "10.1145/3322276.3322322"}, "url": "https://www.semanticscholar.org/paper/2623a1013a7c9cbce39961d69e7eee83bdbfc0c5", "title": "Dead Angles of Personalization: Integrating Curation Algorithms in the Fabric of Design", "abstract": "The amount of information available on the web is too vast for individuals to be able to process it all. To cope with this issue, digital platforms started relying on algorithms to curate, filter and recommend content to their users. This problem has generally been envisioned from a technical perspective, as an optimization issue and has been mostly untouched by design considerations. Through 16 interviews with daily users of platforms, we analyze how curation algorithms influence their daily experience and the strategies they use to try to adapt them to their own needs. Based on these empirical findings, we propose a set of four speculative design alternatives to explore how we can integrate curation algorithms as part of the larger fabric of design on the web. By exploring interactions to counter the binary nature of curation algorithms, their uniqueness, their anti-historicity and their implicit data collection, we provide tools to bridge the current divide between curation algorithms and people.", "venue": "Conference on Designing Interactive Systems", "year": 2019, "referenceCount": 57, "citationCount": 4, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "25226061", "name": "Nolwenn Maudet"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "27517cb723ae6134c3651f262970c185d41d18c6", "externalIds": {"DBLP": "journals/pacmhci/WolfB19", "MAG": "2982773700", "DOI": "10.1145/3359245"}, "url": "https://www.semanticscholar.org/paper/27517cb723ae6134c3651f262970c185d41d18c6", "title": "Evaluating the Promise of Human-Algorithm Collaborations in Everyday Work Practices", "abstract": "Human-algorithm interaction is a growing phenomenon of interest as the use of machine learning (ML) capabilities in everyday technologies becomes more commonplace. In the workplace, such developments raise questions about how people not only make sense of algorithmic actions, but also figure out ways to collaborate with tools and systems that integrate algorithmic outputs. We draw on a field study of IT infrastructure design and report on the experiences of highly-skilled IT architects with the natural language processing (NLP) capabilities in an intelligent system under development to support their solution design work. While architects were supportive of the potential of NLP to enhance their solutioning work, they faced challenges in integrating such capabilities into their existing collaborative work practices. We discuss how these findings add nuance and complexity to discourse around the future of work.", "venue": "Proc. ACM Hum. Comput. Interact.", "year": 2019, "referenceCount": 132, "citationCount": 13, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "39440857", "name": "Christine T. Wolf"}, {"authorId": "144383565", "name": "Jeanette L. Blomberg"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "2a17b7057f093f7e9a98c2f829487c03f35cafba", "externalIds": {"MAG": "2988385865", "DBLP": "journals/pacmhci/WuPS19", "DOI": "10.1145/3359321"}, "url": "https://www.semanticscholar.org/paper/2a17b7057f093f7e9a98c2f829487c03f35cafba", "title": "Agent, Gatekeeper, Drug Dealer", "abstract": "Online content creators have to manage their relations with opaque, proprietary algorithms that platforms employ to rank, filter, and recommend content. How do content creators make sense of these algorithms and what does that teach us about the roles that algorithms play in the social world? We take the case of YouTube because of its widespread use and the spaces for collective sense-making and mutual aid that content creators (YouTubers) have built within the last decade. We engaged with YouTubers in one-on-one interviews, performed content analysis on YouTube videos that discuss the algorithm, and conducted a wiki survey on YouTuber online groups. This triangulation of methodologies afforded us a rich understanding of content creators' understandings, priorities, and wishes as they relate to the algorithm. We found that YouTubers assign human characteristics to the algorithm to explain its behavior; what we have termed algorithmic personas. We identify three main algorithmic personas on YouTube: Agent, Gatekeeper, and Drug Dealer. We propose algorithmic personas as a conceptual framework that describes the new roles that algorithmic systems take on in the social world. As we face new challenges around the ethics and politics of algorithmic platforms such as YouTube, algorithmic personas describe roles that are familiar and can help develop our understanding of algorithmic power relations and accountability mechanisms.", "venue": "Proc. ACM Hum. Comput. Interact.", "year": 2019, "referenceCount": 119, "citationCount": 4, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1406253304", "name": "Eva Yiwei Wu"}, {"authorId": "122223508", "name": "Emily Pedersen"}, {"authorId": "34827715", "name": "Niloufar Salehi"}]}}, {"contexts": ["They highlight how functional theories on algorithmic processes are built despite users\u2019 ostensive lack of technical knowledge (e.g. Bucher, 2017; DeVito et al., 2017; Eslami et al., 2016; Myers West, 2018)."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "300eba4cb0120e606ebe7efbc31da1aa55d8d6b8", "externalIds": {"MAG": "2951551356", "DBLP": "journals/nms/Bishop19", "DOI": "10.1177/1461444819854731"}, "url": "https://www.semanticscholar.org/paper/300eba4cb0120e606ebe7efbc31da1aa55d8d6b8", "title": "Managing visibility on YouTube through algorithmic gossip", "abstract": "Beauty vloggers\u2019 feminised outputs often position them outside of traditional spheres of technical expertise, however, their strategic management of algorithmic visibility makes them an illuminating source of algorithmic knowledge. I draw from an ethnography of beauty vloggers and industry stakeholders to study the collaborative and directive processes used to formulate and sustain algorithmic expertise \u2013 algorithmic gossip. Algorithmic gossip is defined as communally and socially informed theories and strategies pertaining to recommender algorithms, shared and implemented to engender financial consistency and visibility on algorithmically structured social media platforms. Gossip is productive: community communication and talk informs and supports practices such as uploading frequently and producing feminised beauty content to perform more effectively on YouTube. Taking gossip seriously can present a valuable resource for revealing information about how algorithms work and have worked, in addition to revealing how perceptions of algorithms inform content production.", "venue": "New Media Soc.", "year": 2019, "referenceCount": 69, "citationCount": 53, "influentialCitationCount": 4, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144321280", "name": "Sophie Bishop"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "43912762b4352c764670702cf9f879d83ac9bffa", "externalIds": {"MAG": "3000593137"}, "url": "https://www.semanticscholar.org/paper/43912762b4352c764670702cf9f879d83ac9bffa", "title": "Probabilistic Algorithms, Lean Methodology Techniques, and Cell Optimization Results", "abstract": "Probabilistic Algorithms, Lean Methodology Techniques, and Cell Optimization Results by Michael McCurrey MS, Walden University, 2015 MBA, Ottawa University, 2013 BA, Ottawa University, 2011 Doctoral Study Submitted in Partial Fulfillment of the Requirements for the Degree of Doctor of Information Technology Walden University December 2019 Abstract There is a significant technology deficiency within the U.S. manufacturing industry compared to other countries. To adequately compete in the global market, lean manufacturing organizations in the United States need to look beyond their traditional methods of evaluating their processes to optimize their assembly cells for efficiency. Utilizing the task-technology fit theory this quantitative correlational study examined the relationships among software using probabilistic algorithms, lean methodology techniques, and manufacturer cell optimization results. Participants consisted of individuals performing the role of the systems analyst within a manufacturing organization using lean methodologies in the Southwestern United States. Data were collected from 118 responses from systems analysts through a survey instrument, which was an integration of two instruments with proven reliability. Multiple regression analysis revealed significant positive relationships among software using probabilistic algorithms, lean methodology, and cell optimization results. These findings may provide management with information regarding the skillsets required for systems analysts to implement software using probabilistic algorithms and lean manufacturing techniques toThere is a significant technology deficiency within the U.S. manufacturing industry compared to other countries. To adequately compete in the global market, lean manufacturing organizations in the United States need to look beyond their traditional methods of evaluating their processes to optimize their assembly cells for efficiency. Utilizing the task-technology fit theory this quantitative correlational study examined the relationships among software using probabilistic algorithms, lean methodology techniques, and manufacturer cell optimization results. Participants consisted of individuals performing the role of the systems analyst within a manufacturing organization using lean methodologies in the Southwestern United States. Data were collected from 118 responses from systems analysts through a survey instrument, which was an integration of two instruments with proven reliability. Multiple regression analysis revealed significant positive relationships among software using probabilistic algorithms, lean methodology, and cell optimization results. These findings may provide management with information regarding the skillsets required for systems analysts to implement software using probabilistic algorithms and lean manufacturing techniques to improve cell optimization results. The findings of this study may contribute to society through the potential to bring sustainable economic improvement to impoverished communities through the implementation of efficient manufacturing solutions with lower capital expenditures. Probabilistic Algorithms, Lean Methodology Techniques, and Cell Optimization Results by Michael McCurrey MS, Walden University, 2015 MBA, Ottawa University, 2013 BA, Ottawa University, 2011 Doctoral Study Submitted in Partial Fulfillment of the Requirements for the Degree of Doctor of Information Technology", "venue": "", "year": 2019, "referenceCount": 137, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1580199535", "name": "Michael McCurrey"}]}}, {"contexts": ["This could represent a feeling of violated expectations, which tends to decrease satisfaction and could result in users perceiving that their goals are not being met and that the system is unfair [11, 17].", "In some cases, users encounter unexpected or confusing information that violates expectations [11, 45] and hints at algorithmic bias [17]."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "83caab7b4427adba799f278aed7f3c57977da3bb", "externalIds": {}, "url": "https://www.semanticscholar.org/paper/83caab7b4427adba799f278aed7f3c57977da3bb", "title": "Explanations as Mechanisms for SupportingAlgorithmic Transparency", "abstract": "Transparency can empower users to make informed choices about how they use an algorithmic decision-making system and judge its potential consequences. However, transparency is often conceptualized by the outcomes it is intended to bring about, not the specifics of mechanisms to achieve those outcomes. We conducted an online experiment focusing on how different ways of explaining Facebook\u2019s News Feed algorithm might affect participants\u2019 beliefs and judgments about the News Feed. We found that all explanations caused participants to become more aware of how the system works, and helped them to determine whether the system is biased and if they can control what they see. The explanations were less effective for helping participants evaluate the correctness of the system\u2019s output, and form opinions about how sensible and consistent its behavior is. We present implications for the design of transparency mechanisms in algorithmic decision-making systems based on these results.", "venue": "", "year": 2019, "referenceCount": 58, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": null, "authors": [{"authorId": "145296363", "name": "E. Rader"}, {"authorId": "36606130", "name": "Kelley Cotter"}, {"authorId": "10750877", "name": "Janghee Cho"}]}}, {"contexts": [", 2015), and visibility of dissenting opinions (DeVito et al., 2017).", "While bias is often perceived as a social issue, this dissertation builds on discourse which sheds light\non how biases also creep into sociotechnical systems (Bozdag, 2013; DeVito et al., 2017; Lee et al., 2015; Lustig andNardi, 2015; Rader andGray, 2015).", "\u2026continues to show perverse consequences for society, particularly as capitalist structures and private interests influence the outcomes of search engine results (Noble, 2018), availability of gig economy\n131\nemployment (Lee et al., 2015), and visibility of dissenting opinions (DeVito et al., 2017).", "As such, scholarship has found that technical systems can serve to reinforce systemic biases (Lee et al., 2015; Lustig andNardi, 2015), which can have impact on people\u2019s daily lives (DeVito et al., 2017; Rader andGray, 2015).", "While bias is often perceived as a social issue, this dissertation builds on discourse which sheds light on how biases also creep into sociotechnical systems (Bozdag, 2013; DeVito et al., 2017; Lee et al., 2015; Lustig andNardi, 2015; Rader andGray, 2015).", ", 2015; Lustig andNardi, 2015), which can have impact on people\u2019s daily lives (DeVito et al., 2017; Rader andGray, 2015)."], "isInfluential": true, "intents": ["background"], "citingPaper": {"paperId": "8a09bc0e667d01e87f627d4d0593d7148541158f", "externalIds": {"MAG": "2992481842"}, "url": "https://www.semanticscholar.org/paper/8a09bc0e667d01e87f627d4d0593d7148541158f", "title": "Identity Work of Asian Americans and Pacific Islanders on Reddit: Traversals of Deliberation, Moderation, and Decolonization", "abstract": "Marginalized groups experience issues inmanaging their identities for a variety of reasons, and online spaces afford them the opportunity tomake sense of and revise their intersectional identities. One such group is Asian Americans and Pacific Islanders (AAPIs), who are at the receiving end of stereotypes that oftenmanifest in inaccurate public perceptions. The dissertation consists of three empirical studies that disentangle howAAPIs construct and express their identity in online communities within Reddit: 1. The first study examines how users engage in an online community through a deliberation lens to understand the extent to which Reddit supports identity work as a deliberative process. Through a content analysis of 4,406Reddit comments collected during the 2016US Presidential Election, I discuss how the expression of identity, and thereby solidarity, in a politicized online settingmay lead to a social movement. 2. The second study uncovers howmoderators on Reddit shape the norms of their subreddit through the analytic lens of emotional labor. I conduct interviewswith 21moderators who facilitate identity work discourse in AAPI subreddits, present a thematic analysis of their moderation practices, offer recommendations for improvingmoderation in online communities centered around identity work, and discuss implications of emotional labor in the design of Reddit and similar platforms. 3. The third study examinesmarginalization through the analytic framework of decolonization, uncovering the threats and tactics that AAPI redditors encounter and employ to decolonize their collective identity. I find that moderators of AAPI subreddits develop collective resiliencewithin their online communities by reclaiming space to confront brigade invasion, recording collective memory to circumvent systemic erasure, and revising cultural narratives to deconstruct colonial mentality. I discuss how algorithmic configurations within sociotechnical systems reaffirm existing hegemonic values and describe ways in which redditors maywork toward resistance. These three studies are woven together to uncover ways in which AAPIs negotiate collective action in the context of online identity work. IdentityWork of Asian Americans and Pacific Islanders on Reddit: Traversals of Deliberation, Moderation, andDecolonization", "venue": "", "year": 2019, "referenceCount": 272, "citationCount": 2, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Political Science"], "authors": [{"authorId": "1909948", "name": "Bryan Dosono"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "8f904555d25d8cc4919d760d686f93ec5bf5ee05", "externalIds": {"DOI": "10.5210/spir.v2019i0.11001"}, "url": "https://www.semanticscholar.org/paper/8f904555d25d8cc4919d760d686f93ec5bf5ee05", "title": "HOW DOES CRYSTAL KNOW? FOLK THEORIES AND TRUST IN PREDICTIVE ALGORITHMS THAT ASSESS INDIVIDUAL PERSONALITY AND COMMUNICATION PREFERENCES", "abstract": "In recent years, there has been a rise in predictive algorithms that focus on individual preferences and psychometric assessments. The idea is that an individual social media presence may give off unconscious cues or indicators of a person's personality. While there has been a growing body of research into people's reactions, perceptions, and folk theories of how algorithms work, there has been a growing need for research into these hyper-personal algorithms and profiles. This study focuses on a company called CrystalKnows, which purports to have the largest database of personality profiles in the world, many of which are generated without an individual's explicit consent. Through qualitative interviews (n=31) with people after being presented with their own profile, this study explores how people perceive the profiles, where they believe the information is coming from, and what contexts they would be comfortable with their profile being used. Crystal profiles also contain predictions about how people will communicate and potentially work together in teams with people of other personality dispositions, which also raises concerns about inaccurate assessments or discrimination based on these profiles. The findings from this study and how people rationalize these algorithms not only builds on our understanding of algorithmic perception and folk theories, but also has important practical implications for the trust in these systems and the continued deployment of hyper-personal predictive algorithms.", "venue": "AoIR Selected Papers of Internet Research", "year": 2019, "referenceCount": 8, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": null, "authors": [{"authorId": "32389539", "name": "Tony Liao"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "9eab230e72e492dd23e34d536a1dbb2d729924d7", "externalIds": {"MAG": "2922838818"}, "url": "https://www.semanticscholar.org/paper/9eab230e72e492dd23e34d536a1dbb2d729924d7", "title": "How Do Intermediaries Shape News-Related Media Repertoires and Practices? Findings From a Qualitative Study", "abstract": "Online intermediaries such as search engines, social network sites, or video platforms provide access to diverse content; however, there is a school of thought that argues that they may also contribute to the structural deformation of the public sphere. To assess the impact of these Web-based services, research needs to address them not as isolated platforms but as part of broader media environments. Based on 6 group discussions and 18 interviews with German participants varying in age and political engagement, we mapped individual information repertoires with a particular focus on online intermediaries, reconstructed key episodes in which these services were used for gathering information on current news events, and investigated participants\u2019 awareness of the architecture and mechanisms of these intermediaries. Findings show that for most participants, online intermediaries are an indispensable part of their media repertoires, but are seldom dominant, let alone the only source of information on political topics. Most respondents possessed some knowledge on the basic workings of the intermediaries they used, but were not familiar with details such as algorithmic personalization.", "venue": "", "year": 2019, "referenceCount": 60, "citationCount": 18, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Sociology"], "authors": [{"authorId": "1739571336", "name": "Jan-Hinrik Schmidt"}, {"authorId": "46736494", "name": "Lisa Merten"}, {"authorId": "73699507", "name": "Uwe Hasebrink"}, {"authorId": "118635479", "name": "Isabelle Petrich"}, {"authorId": "118773061", "name": "A. Rolfs"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "e6649afaacb63fbba1efe5a7e5deb304b22dd043", "externalIds": {"DBLP": "conf/chi/EslamiVLOGK19", "MAG": "2940680165", "DOI": "10.1145/3290605.3300724"}, "url": "https://www.semanticscholar.org/paper/e6649afaacb63fbba1efe5a7e5deb304b22dd043", "title": "User Attitudes towards Algorithmic Opacity and Transparency in Online Reviewing Platforms", "abstract": "Algorithms exert great power in curating online information, yet are often opaque in their operation, and even existence. Since opaque algorithms sometimes make biased or deceptive decisions, many have called for increased transparency. However, little is known about how users perceive and interact with potentially biased and deceptive opaque algorithms. What factors are associated with these perceptions, and how does adding transparency into algorithmic systems change user attitudes? To address these questions, we conducted two studies: 1) an analysis of 242 users' online discussions about the Yelp review filtering algorithm and 2) an interview study with 15 Yelp users disclosing the algorithm's existence via a tool. We found that users question or defend this algorithm and its opacity depending on their engagement with and personal gain from the algorithm. We also found adding transparency into the algorithm changed users' attitudes towards the algorithm: users reported their intention to either write for the algorithm in future reviews or leave the platform.", "venue": "CHI", "year": 2019, "referenceCount": 64, "citationCount": 43, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2419451", "name": "Motahhare Eslami"}, {"authorId": "2862178", "name": "Kristen Vaccaro"}, {"authorId": "50112472", "name": "Min Kyung Lee"}, {"authorId": "41071284", "name": "Amit Elazari Bar On"}, {"authorId": "145280613", "name": "Eric Gilbert"}, {"authorId": "1680270", "name": "K. Karahalios"}]}}, {"contexts": ["Algorithmic folk theories often emerge and take shape at moments of rupture, such as when a service like Facebook, Twitter, or Instagram announces a change in the algorithm (DeVito et al., 2017)."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "e8c056c796b5c3bdba444fe0d945139f0f356fa7", "externalIds": {"MAG": "2984492189", "DOI": "10.1177/2056305119879995"}, "url": "https://www.semanticscholar.org/paper/e8c056c796b5c3bdba444fe0d945139f0f356fa7", "title": "\u201cGaming the System\u201d: Platform Paternalism and the Politics of Algorithmic Visibility", "abstract": "As the logic of data-driven metrification reconfigures various realms of social and economic life, cultural workers\u2014from journalists and musicians to photographers and social media content creators\u2014are pursuing online visibility in earnest. Despite workers\u2019 patterned deployment of search engine optimization, reciprocal linking, and automated engagement-boosting, tech companies routinely denigrate such practices as gaming the system. This article critically probes discourses and practices of so-called system-gaming by analyzing three key moments when platforms accused cultural producers of algorithmic manipulation. Empirically, we draw upon textual analyses of news articles (n\u2009=\u2009105) and user guidelines published by Google, Facebook, and Instagram. Our findings suggest that the line between what platforms deem illegitimate algorithmic manipulation and legitimate strategy is nebulous and largely reflective of their material interests. However, the language used to invoke this distinction is strongly normative, condemning \u201csystem gamers\u201d as morally bankrupt, while casting platform companies as neutral actors working to uphold the ideals of authenticity and integrity. We term this dynamic \u201cplatform paternalism\u201d and conclude that gaming accusations constitute an important mechanism through which platforms legitimate their power and authority, to the detriment of less well-established cultural producers.", "venue": "Social Media + Society", "year": 2019, "referenceCount": 109, "citationCount": 28, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": ["Sociology"], "authors": [{"authorId": "117028828", "name": "Caitlin Petre"}, {"authorId": "20537832", "name": "B. Duffy"}, {"authorId": "21108509", "name": "Emily Hund"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "1f055181e11f5ef4dce950291238e1e55b18d0b1", "externalIds": {"MAG": "2799792670", "DOI": "10.1177/2056305118768301"}, "url": "https://www.semanticscholar.org/paper/1f055181e11f5ef4dce950291238e1e55b18d0b1", "title": "Do Algorithms Shape Character? Considering Algorithmic Ethical Subjectivation", "abstract": "Moral critiques of computational algorithms seem divided between two paradigms. One seeks to demonstrate how an opaque and unruly algorithmic power violates moral values and harms users\u2019 autonomy; the other underlines the systematicity of such power, deflating concerns about opacity and unruliness. While the second paradigm makes it possible to think of end users of algorithmic systems as moral agents, the consequences of this possibility remain unexplored. This article proposes one way of tackling this problem. Employing Michel Foucault\u2019s version of virtue ethics, I examine how perceptions of Facebook\u2019s normative regulation of visibility have transformed non-expert end users\u2019 ethical selves (i.e., their character) in the current political crisis in Brazil. The article builds on this analysis to advance algorithmic ethical subjectivation as a concept to make sense of these processes of ethical becoming. I define them as plural (encompassing various types of actions and values, and resulting in no determinate subject), contextual (demanding not only sociomaterial but also epistemological and ethical conditions), and potentially harmful (eventually structuring harms that are not externally inflicted by algorithms, but by users, upon themselves and others, in response to how they perceive the normativity of algorithmic decisions). By researching which model(s) of ethical subjectivation specific algorithmic social platforms instantiate, critical scholars might be able to better understand the normative consequences of these platforms\u2019 power.", "venue": "", "year": 2018, "referenceCount": 98, "citationCount": 7, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Sociology"], "authors": [{"authorId": "32552576", "name": "Jo\u00e3o Carlos Magalh\u00e3es"}]}}, {"contexts": ["This could represent a feeling of violated expectations, which tends to decrease satisfaction and could result in users perceiving that their goals are not being met and that the system is unfair [11, 17].", "In some cases, users encounter unexpected or confusing information that violates expectations [11, 45] and hints at algorithmic bias [17]."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "613ce903cc1102d2adfff14ec37ba433f752555e", "externalIds": {"DBLP": "conf/chi/RaderCC18", "MAG": "2796133875", "DOI": "10.1145/3173574.3173677"}, "url": "https://www.semanticscholar.org/paper/613ce903cc1102d2adfff14ec37ba433f752555e", "title": "Explanations as Mechanisms for Supporting Algorithmic Transparency", "abstract": "Transparency can empower users to make informed choices about how they use an algorithmic decision-making system and judge its potential consequences. However, transparency is often conceptualized by the outcomes it is intended to bring about, not the specifics of mechanisms to achieve those outcomes. We conducted an online experiment focusing on how different ways of explaining Facebook's News Feed algorithm might affect participants' beliefs and judgments about the News Feed. We found that all explanations caused participants to become more aware of how the system works, and helped them to determine whether the system is biased and if they can control what they see. The explanations were less effective for helping participants evaluate the correctness of the system's output, and form opinions about how sensible and consistent its behavior is. We present implications for the design of transparency mechanisms in algorithmic decision-making systems based on these results.", "venue": "CHI", "year": 2018, "referenceCount": 60, "citationCount": 137, "influentialCitationCount": 5, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145296363", "name": "E. Rader"}, {"authorId": "36606130", "name": "Kelley Cotter"}, {"authorId": "10750877", "name": "Janghee Cho"}]}}, {"contexts": ["Several researchers define online records of human activity as \u201csocial sensors\u201d and have proposed utilizing them [2][3], while HCI studies have also started to use these online activities as data [4][5][6]."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "651fa92828178992062fa4533e4419b6e9fe48e9", "externalIds": {"MAG": "2802251580"}, "url": "https://www.semanticscholar.org/paper/651fa92828178992062fa4533e4419b6e9fe48e9", "title": "\u201cIt\u2019s Public, and also Private\u201d: An Analysis of Flaming Fan Studies", "abstract": "Online services make users\u2019 communication activities and content public. This online information has contributed to accelerating the creation cycle of user-generated content. Moreover, these services also allow researchers to utilize these online texts as a public source for easily analyzing human activities, also referred to as social sensing studies. However, we need to realize that there exists a controversial problem of privacy especially in the sensitive areas of creation, even though the content is public. This study tries to create new guidelines for online study using the case of the flaming of a study of female fan-fiction, which attempted to extract and filter sexual expressions using online fan-fiction novels as source. Researchers from the fields of both engineering and humanities, including law and ethics, discussed the violations in this case, and extracted ethical, legal, and social issues according to their specific areas of expertise. Internet technologies allow human communication to become much more tractable and observable. SNS and other networking services attract users to upload their activities online, eliciting social rewards. Maker Movements like Fablab, and the user generated content (UGC) movement also appreciate this form of shared information for enhancing the creation cycle of users supported by upload and feedback [1]. These online content platforms are a good research source, or hidden treasure, for evaluating and analyzing society\u2019s activities. Several researchers define online records of human activity as \u201csocial sensors\u201d and have proposed utilizing them [2][3], while HCI studies have also started to use these online activities as data [4][5][6]. However, we also need to be careful that these public texts are not just open information for the research. The boundaries of public and private information are ambiguous, because users are not always aware of or have agreed to the fact that their content is to be openly used. Several researchers have voiced the criticism that the binarized notion of public and private is not appropriate in today\u2019s Internet environment [7][8]. In 2008, a group of researchers released profile data collected from Facebook accounts of US university students, leading to controversial discussion [9]. This mismatch between user and researcher requires new ethical guidelines for online studies [10]. Regarding the handling of information on the Internet, the Association of Internet Research Ethics Working Committee provides guidelines on human online activities [11] Our viewpoint on the study by the abovementioned researchers is that not only user attribution, but also user content causes this kind of discussion on the border between public and private. These situations become critical in studies on UGC. Usually, every piece of published fiction is required to be separately accepted and criticized from the author\u2019s private attribution in a literature context. The author\u2019s privacy is protected by their name is anonymized by a pen name. However, these published contents may be regarded as private content, especially in sensitive fiction by minorities. Guidelines are starting to be created in the area of fan studies [12]. How The 32nd Annual Conference of the Japanese Society for Artificial Intelligence, 2018", "venue": "", "year": 2018, "referenceCount": 18, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Sociology"], "authors": [{"authorId": "145978249", "name": "Hirotaka Osawa"}]}}, {"contexts": ["Reactions to changes in algorithms reveal that people have particular expectations of platforms, and DeVito et al. (2017) recorded tweets identifying that a key part of Twitter was violated through the change from a chronologic to algorithmically curated timeline:\nJust don\u2019t, @twitter.", ", 2015), \u2018imaginary expectations\u2019 (Seyfert and Roberge, 2016), \u2018folk theories\u2019 (DeVito et al., 2017) and \u2018intuitive causal explanatory theories\u2019 (Rader and Gray, 2015) about how they work.", "\u2026a programmer does about the specific code of an algorithm, they still hold \u2018perceived knowledge\u2019 (Eslami et al., 2015), \u2018imaginary expectations\u2019 (Seyfert and Roberge, 2016), \u2018folk theories\u2019 (DeVito et al., 2017) and \u2018intuitive causal explanatory theories\u2019 (Rader and Gray, 2015) about how they work.", "DeVito et al. (2017) looked at tweets about algorithms to better understand folk theories about how they work."], "isInfluential": true, "intents": ["background"], "citingPaper": {"paperId": "7fd42a6616ac2779ab59c0bc021a30e068f4a383", "externalIds": {"DOI": "10.1177/1329878X18783002"}, "url": "https://www.semanticscholar.org/paper/7fd42a6616ac2779ab59c0bc021a30e068f4a383", "title": "\u2018Networks that work too well\u2019: intervening in algorithmic connections", "abstract": "Within the emerging field of critical algorithm studies, this article theorises that forced connections happen when algorithms exacerbate human actions in connecting otherwise disparate data points on digitally networked platforms to the subject of the data\u2019s detriment. Although social media users may not have a comprehensive understanding of how algorithms work to make some content visible, when users form their own explanatory theories about these algorithms, they often intervene in these connections. Drawing on Michel de Certeau\u2019s notion of strategies as the manipulations in which platforms engage to profile and control their users, and tactics as everyday acts of resistance, this article investigates two tactics within algorithmic cultures \u2013 Voldemorting, or not mentioning words or names in order to avoid a forced connection; and screenshotting, or making content visible without sending its website traffic \u2013 to demonstrate users\u2019 understandings of the algorithms that seek to connect individuals to other people, platforms, content and advertisers, and their efforts to wrest back control.", "venue": "Media International Australia", "year": 2018, "referenceCount": 78, "citationCount": 4, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": null, "authors": [{"authorId": "1680769044", "name": "Emily van der Nagel"}]}}, {"contexts": ["Either too much or too little transparency in the design and documentation of an algorithm can create situations of distrust (DeVito, Gergle, and Birnholtz 2017)."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "900b23ea09e99218604f05dd8ec25bfbdbbdcfe3", "externalIds": {"MAG": "2754525251", "DOI": "10.1080/21670811.2017.1366865"}, "url": "https://www.semanticscholar.org/paper/900b23ea09e99218604f05dd8ec25bfbdbbdcfe3", "title": "Coding the News", "abstract": "This article examines the role of code in the process of news distribution and the degree to which code and algorithms can filter and prioritize news, much as an editor would. The discussion focuses specifically on the context of mobile news applications that filter news for consumers. Given concerns raised by the intersection of computer science and journalism, analysis moves away from the common notion that code is replacing humans as producers of news and shifts toward the role of code in helping journalists order and communicate the news. Thus, the focus of this research is on code as technological actants, filtering news based on decisions imbued into the code by human actors. This article reports the results of an investigation of code contained in 59 open source mobile news apps and an analysis of the content of that code. Findings highlight the journalistic decisions made in code and contribute to discussion surrounding the relationship between algorithmic and traditional news values.", "venue": "", "year": 2018, "referenceCount": 83, "citationCount": 16, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2110604214", "name": "Matthew S. Weber"}, {"authorId": "71167187", "name": "Allie Kosterich"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "a9611b04db42638c236efd1428e11b66b449c8bc", "externalIds": {"MAG": "2796239588", "DBLP": "conf/chi/DeVitoBHFL18", "DOI": "10.1145/3173574.3173694"}, "url": "https://www.semanticscholar.org/paper/a9611b04db42638c236efd1428e11b66b449c8bc", "title": "How People Form Folk Theories of Social Media Feeds and What it Means for How We Study Self-Presentation", "abstract": "Self-presentation is a process that is significantly complicated by the rise of algorithmic social media feeds, which obscure information about one's audience and environment. User understandings of these systems, and therefore user ability to adapt to them, are limited, and have recently been explored through the lens of folk theories. To date, little is understood of how these theories are formed, and how they tie to the self-presentation process in social media. This paper presents an exploratory look at the folk theory formation process and the interplay between folk theories and self-presentation via a 28-participant interview study. Results suggest that people draw from diverse sources of information when forming folk theories, and that folk theories are more complex, multifaceted and malleable than previously assumed. This highlights the need to integrate folk theories into both social media systems and theories of self-presentation.", "venue": "CHI", "year": 2018, "referenceCount": 60, "citationCount": 67, "influentialCitationCount": 7, "isOpenAccess": false, "fieldsOfStudy": ["Sociology", "Computer Science"], "authors": [{"authorId": "32861190", "name": "M. DeVito"}, {"authorId": "1797153", "name": "Jeremy P. Birnholtz"}, {"authorId": "1697703", "name": "J. Hancock"}, {"authorId": "143667081", "name": "Megan French"}, {"authorId": "32292671", "name": "S. Liu"}]}}, {"contexts": ["But in the absence of transparency from platform providers, end-users may develop folk theories of algorithms, leading to a diverse range of strategies and countermeasures with varying degrees of effectiveness [22, 14]."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "aba609e6c5c9b58f9dac272b75983f75a7f190e5", "externalIds": {"MAG": "2786004891", "ArXiv": "1801.10408", "DBLP": "conf/chi/BinnsKVLZS18", "DOI": "10.1145/3173574.3173951"}, "url": "https://www.semanticscholar.org/paper/aba609e6c5c9b58f9dac272b75983f75a7f190e5", "title": "'It's Reducing a Human Being to a Percentage': Perceptions of Justice in Algorithmic Decisions", "abstract": "Data-driven decision-making consequential to individuals raises important questions of accountability and justice. Indeed, European law provides individuals limited rights to 'meaningful information about the logic' behind significant, autonomous decisions such as loan approvals, insurance quotes, and CV filtering. We undertake three experimental studies examining people's perceptions of justice in algorithmic decision-making under different scenarios and explanation styles. Dimensions of justice previously observed in response to human decision-making appear similarly engaged in response to algorithmic decisions. Qualitative analysis identified several concerns and heuristics involved in justice perceptions including arbitrariness, generalisation, and (in)dignity. Quantitative analysis indicates that explanation styles primarily matter to justice perceptions only when subjects are exposed to multiple different styles---under repeated exposure of one style, scenario effects obscure any explanation effects. Our results suggests there may be no 'best' approach to explaining algorithmic decisions, and that reflection on their automated nature both implicates and mitigates justice dimensions.", "venue": "CHI", "year": 2018, "referenceCount": 99, "citationCount": 195, "influentialCitationCount": 13, "isOpenAccess": true, "fieldsOfStudy": ["Psychology", "Computer Science"], "authors": [{"authorId": "144147883", "name": "R. Binns"}, {"authorId": "2341082", "name": "M. V. Kleek"}, {"authorId": "33699440", "name": "Michael Veale"}, {"authorId": "3370153", "name": "Ulrik Lyngs"}, {"authorId": "144693633", "name": "Jun Zhao"}, {"authorId": "1705314", "name": "N. Shadbolt"}]}}, {"contexts": ["Many researchers have explored sensemaking around social media and news feeds [7, 12, 18, 20, 48].", "\u2019s study of folk theories of algorithmic curation of the Twitter news feed showed that users\u2019 resistance to algorithmically curated news feeds is often driven by violated expectations [12]."], "isInfluential": false, "intents": ["background"], "citingPaper": {"paperId": "b5406515285b8345f640d36d3d0d6658a43be543", "externalIds": {"MAG": "2795737619", "DBLP": "conf/chi/VaccaroHESHK18", "DOI": "10.1145/3173574.3173590"}, "url": "https://www.semanticscholar.org/paper/b5406515285b8345f640d36d3d0d6658a43be543", "title": "The Illusion of Control: Placebo Effects of Control Settings", "abstract": "Algorithmic prioritization is a growing focus for social media users. Control settings are one way for users to adjust the prioritization of their news feeds, but they prioritize feed content in a way that can be difficult to judge objectively. In this work, we study how users engage with difficult-to-validate controls. Via two paired studies using an experimental system -- one interview and one online study -- we found that control settings functioned as placebos. Viewers felt more satisfied with their feed when controls were present, whether they worked or not. We also examine how people engage in sensemaking around control settings, finding that users often take responsibility for violated expectations -- for both real and randomly functioning controls. Finally, we studied how users controlled their social media feeds in the wild. The use of existing social media controls had little impact on user's satisfaction with the feed; instead, users often turned to improvised solutions, like scrolling quickly, to see what they want.", "venue": "CHI", "year": 2018, "referenceCount": 76, "citationCount": 23, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Psychology", "Computer Science"], "authors": [{"authorId": "2862178", "name": "Kristen Vaccaro"}, {"authorId": "40959022", "name": "Dylan Huang"}, {"authorId": "2419451", "name": "Motahhare Eslami"}, {"authorId": "1829115", "name": "Christian Sandvig"}, {"authorId": "2072368141", "name": "Kevin Hamilton"}, {"authorId": "1680270", "name": "K. Karahalios"}]}}, {"contexts": ["In the existing literature, methods range from direct elicitation via interviews and walkthroughs [4, 6] to survey work [1] and indirect elicitation via analysis of public tweets [5].", "In particular, we have turned to user folk theories or lay understandings as an analytical frame, using this lens to explore topics including audience perception [1], algorithmic understanding [6], self-presentation [4], how platforms are affectively perceived [7], and user resistance to algorithmic change [5].", "found that, in addition to these higherlevel folk theories, there are abstract theories employed by users with minimal knowledge on the level of algorithm as mysterious influence and interloper [5], while work by French and Hancock posited folk theory understanding via operational metaphors through which users frame the algorithmic system [7].", ", [4, 5, 6, 7]) explicitly addresses black-boxed platform algorithms and often does so from academia, with the black box fully intact."], "isInfluential": false, "intents": ["background", "methodology"], "citingPaper": {"paperId": "dbb99c627f0209c1d6466538755915b2164e3fe9", "externalIds": {"DBLP": "conf/chi/DeVitoHFBAKTS18", "MAG": "2795580035", "DOI": "10.1145/3170427.3186320"}, "url": "https://www.semanticscholar.org/paper/dbb99c627f0209c1d6466538755915b2164e3fe9", "title": "The Algorithm and the User: How Can HCI Use Lay Understandings of Algorithmic Systems?", "abstract": "In studying the increasing role that opaque, algorithmically-driven systems, such as social media feeds, play in society and people's everyday lives, user folk theories are emerging as one powerful lens with which to examine the relationship between user and algorithmic system. Folk theories allow researchers to better see from users' own perspectives how they understand these systems and how their understanding impacts their behavior. However, this approach is still new. Methods, interpretation, and future directions are up for debate. This panel will be an active discussion of the contribution of folk theories to HCI to date, how to advance a folk theory perspective, and how this perspective can bridge academic and industry study of these systems. Our panel gathers key folk theory HCI researchers from academia and industry to share their perspectives and engage the CHI audience.", "venue": "CHI Extended Abstracts", "year": 2018, "referenceCount": 13, "citationCount": 16, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Sociology"], "authors": [{"authorId": "32861190", "name": "M. DeVito"}, {"authorId": "1697703", "name": "J. Hancock"}, {"authorId": "143667081", "name": "Megan French"}, {"authorId": "1797153", "name": "Jeremy P. Birnholtz"}, {"authorId": "2670187", "name": "J. Antin"}, {"authorId": "1680270", "name": "K. Karahalios"}, {"authorId": "3106046", "name": "Stephanie Tom Tong"}, {"authorId": "2692274", "name": "Irina A. Shklovski"}]}}, {"contexts": ["concluded that users\u2019 resistance to algorithmic change are shaped by their folk-theory based understandings of algorithmically-driven systems [12].", "In a study of user backlash to rumors about introduction of algorithmic curation to Twitter\u2019s timeline, DeVito et al. concluded that users\u2019 resistance to algorithmic change are shaped by their folk-theory based understandings of algorithmically-driven systems [12].", "Gillespie explored the controversy over Twitter trends and accusations of algorithmic censorship of the tag #occupywallstreet and inferred that \u201cthere is a tension between what we understand these algorithms to be, what we need them to be, and what they in fact are\u201d [20].", "Recent studies in HCI have taken an active interest in user awareness and misunderstanding of algorithms that drive complex online platforms like Facebook and Twitter [12, 17, 18, 19, 26, 35]."], "isInfluential": true, "intents": ["background"], "citingPaper": {"paperId": "edfbbb45cb7b630d35497707e93ffd6b19f89c82", "externalIds": {"DBLP": "conf/chi/JhaverKA18", "MAG": "2795695399", "DOI": "10.1145/3173574.3173995"}, "url": "https://www.semanticscholar.org/paper/edfbbb45cb7b630d35497707e93ffd6b19f89c82", "title": "Algorithmic Anxiety and Coping Strategies of Airbnb Hosts", "abstract": "Algorithms increasingly mediate how work is evaluated in a wide variety of work settings. Drawing on our interviews with 15 Airbnb hosts, we explore the impact of algorithmic evaluation on users and their work practices in the context of Airbnb. Our analysis reveals that Airbnb hosts engage in a double negotiation on the platform: They must negotiate efforts not just to attract potential guests but also to appeal to only partially transparent evaluative algorithms. We found that a perceived lack of control and uncertainty over how algorithmic evaluation works can create anxiety among some Airbnb hosts. We present a framework for understanding this double negotiation, as well as a case study of coping strategies that hosts employ to deal with their anxiety. We conclude with a discussion of design solutions that can help reduce algorithmic anxiety and increase confidence in algorithmic systems.", "venue": "CHI", "year": 2018, "referenceCount": 51, "citationCount": 45, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Psychology"], "authors": [{"authorId": "3362498", "name": "Shagun Jhaver"}, {"authorId": "40964277", "name": "Yoni Karpfen"}, {"authorId": "2670187", "name": "J. Antin"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "fe4a5554482d124fc7dff24d3f3bbd7a46ead900", "externalIds": {"DBLP": "conf/chi/DiazJLPG18", "MAG": "2795975316", "DOI": "10.1145/3173574.3173986"}, "url": "https://www.semanticscholar.org/paper/fe4a5554482d124fc7dff24d3f3bbd7a46ead900", "title": "Addressing Age-Related Bias in Sentiment Analysis", "abstract": "Computational approaches to text analysis are useful in understanding aspects of online interaction, such as opinions and subjectivity in text. Yet, recent studies have identified various forms of bias in language-based models, raising concerns about the risk of propagating social biases against certain groups based on sociodemographic factors (e.g., gender, race, geography). In this study, we contribute a systematic examination of the application of language models to study discourse on aging. We analyze the treatment of age-related terms across 15 sentiment analysis models and 10 widely-used GloVe word embeddings and attempt to alleviate bias through a method of processing model training data. Our results demonstrate that significant age bias is encoded in the outputs of many sentiment analysis algorithms and word embeddings. We discuss the models' characteristics in relation to output bias and how these models might be best incorporated into research.", "venue": "CHI", "year": 2018, "referenceCount": 96, "citationCount": 45, "influentialCitationCount": 4, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145457966", "name": "Mark Diaz"}, {"authorId": "11456612", "name": "Isaac L. Johnson"}, {"authorId": "29898555", "name": "Amanda Lazar"}, {"authorId": "2373998", "name": "Anne Marie Piper"}, {"authorId": "2497393", "name": "D. Gergle"}]}}, {"contexts": [], "isInfluential": false, "intents": [], "citingPaper": {"paperId": "3d07e535b2c4edc457a2ab7ff1106fc70e0a4bdf", "externalIds": {"MAG": "2810832454"}, "url": "https://www.semanticscholar.org/paper/3d07e535b2c4edc457a2ab7ff1106fc70e0a4bdf", "title": "Commitment issues: toward an understanding of young people's social media choices in the multi-platform era", "abstract": "Social network sites (SNSs) have become a common part of everyday life for billions of people worldwide. Not everyone uses the same sites, nor are sites functionally equivalent in the eyes of users. Both established platforms and new upstarts may provide novel features or access to new audiences, yet users tend to remain on a few dominant platforms, especially Facebook, the world\u2019s reigning social network site. The goal of the present study is to understand why people are committed to specific social network sites, given that no site encompasses either all of a person\u2019s social connections or all possible gratifications available from online participation. Further, individuals do not always wish to have a single real-name identity for all online interactions, thus implying the necessary use of multiple accounts or sites. To understand SNS commitment, this study employs a mixed-methods research design by combining findings from a survey of 800 respondents with 50 semi-structured interviews. The research focuses on young adults in the UK and their use of four popular SNSs: Facebook, Twitter, Instagram and Snapchat. Findings indicate that network size has only a marginal effect on commitment, whereas the effect of identity performance is more pronounced, albeit in different ways on different sites. Social and informational gratifications have the strongest effect across all four SNSs, suggesting that commitment is primarily driven by repeated habit-forming experiences. To further help explain SNS commitment, this thesis employs a typology of social media users based on attitudes towards digital technology. It is evident that attitudes explain more variation in commitment than either demographic factors or personality. Qualitative analysis reinforces this finding by showing how users employ specific gratification-based repertoires to determine which sites to use and when. These findings help advance research on affordances, self-presentation and SNS use, while also making practical recommendations for social media platforms.", "venue": "", "year": 2017, "referenceCount": 477, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Psychology"], "authors": [{"authorId": "3046490", "name": "Vyacheslav W. Polonski"}]}}]}